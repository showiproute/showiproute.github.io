<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta name="description" content="悟已往之不谏,知来者之可追">
<meta property="og:type" content="website">
<meta property="og:title" content="积累技术之路">
<meta property="og:url" content="http://blogoflyt.cn/page/3/index.html">
<meta property="og:site_name" content="积累技术之路">
<meta property="og:description" content="悟已往之不谏,知来者之可追">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="积累技术之路">
<meta name="twitter:description" content="悟已往之不谏,知来者之可追">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://blogoflyt.cn/page/3/"/>





  <title>积累技术之路</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">积累技术之路</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">找到学习的热爱</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://blogoflyt.cn/2019/02/16/sqoop数据迁移工具-安装配置/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Richard">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/gakki.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="积累技术之路">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/02/16/sqoop数据迁移工具-安装配置/" itemprop="url">sqoop数据迁移工具-----安装配置</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-02-16T20:20:00+08:00">
                2019-02-16
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/sqoop/" itemprop="url" rel="index">
                    <span itemprop="name">sqoop</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>–安装配置<br>author: Richard<br>tags:</p>
<ul>
<li>sqoop</li>
<li>数据迁移<br>categories:</li>
<li>sqoop<br>date: 2019-02-16 20:20:00</li>
</ul>
<hr>
<h5 id="sqoop数据迁移工具"><a href="#sqoop数据迁移工具" class="headerlink" title="sqoop数据迁移工具"></a>sqoop数据迁移工具</h5><h6 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sqoop是apache旗下一款“Hadoop和关系数据库服务器之间传送数据”的工具。</span><br><span class="line">导入数据：MySQL，Oracle导入数据到Hadoop的HDFS、HIVE、HBASE等数据存储系统；</span><br><span class="line">导出数据：从Hadoop的文件系统中导出数据到关系数据库mysql等</span><br></pre></td></tr></table></figure>
<p><a href="https://imgchr.com/i/kzviTA" target="_blank" rel="noopener"><img src="https://s2.ax1x.com/2019/03/08/kzviTA.jpg" alt="kzviTA.jpg"></a></p>
<h6 id="工作机制"><a href="#工作机制" class="headerlink" title="工作机制"></a>工作机制</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">将导入或导出命令翻译成mapreduce程序来实现</span><br><span class="line">在翻译出的mapreduce中主要是对inputformat和outputformat进行定制</span><br></pre></td></tr></table></figure>
<h5 id="sqoop安装"><a href="#sqoop安装" class="headerlink" title="sqoop安装"></a>sqoop安装</h5><blockquote>
<p>安装sqoop的前提是已经具备java和hadoop的环境</p>
<ol>
<li>下载并解压<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">最新版下载地址http://ftp.wayne.edu/apache/sqoop/1.4.6/</span><br></pre></td></tr></table></figure>
</li>
</ol>
</blockquote>
<ol start="2">
<li><p>修改配置文件</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ cd $SQOOP_HOME/conf</span><br><span class="line">$ mv sqoop-env-template.sh sqoop-env.sh</span><br><span class="line">打开sqoop-env.sh并编辑下面几行：</span><br><span class="line">export HADOOP_COMMON_HOME=/home/hadoop/apps/hadoop-2.6.1/ </span><br><span class="line">export HADOOP_MAPRED_HOME=/home/hadoop/apps/hadoop-2.6.1/</span><br><span class="line">export HIVE_HOME=/home/hadoop/apps/hive-1.2.1</span><br></pre></td></tr></table></figure>
</li>
<li><p>加入mysql的jdbc驱动包</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp  ~/app/hive/lib/mysql-connector-java-5.1.28.jar   $SQOOP_HOME/lib/</span><br></pre></td></tr></table></figure>
</li>
<li><p>验证启动</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">$ cd $SQOOP_HOME/bin</span><br><span class="line">$ sqoop-version</span><br><span class="line">预期的输出：</span><br><span class="line">15/12/17 14:52:32 INFO sqoop.Sqoop: Running Sqoop version: 1.4.6</span><br><span class="line">Sqoop 1.4.6 git commit id 5b34accaca7de251fc91161733f906af2eddbe83</span><br><span class="line">Compiled by abe on Fri Aug 1 11:19:26 PDT 2015</span><br><span class="line">到这里，整个Sqoop安装工作完成。</span><br><span class="line"></span><br><span class="line">验证sqoop到mysql业务库之间的连通性：</span><br><span class="line">bin/sqoop-list-databases --connect jdbc:mysql://localhost:3306 --username root --password root</span><br><span class="line">bin/sqoop-list-tables --connect jdbc:mysql://localhost:3306/userdb --username root --password root</span><br></pre></td></tr></table></figure></li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://blogoflyt.cn/2019/02/14/Flume日志采集框架-高可用/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Richard">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/gakki.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="积累技术之路">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/02/14/Flume日志采集框架-高可用/" itemprop="url">Flume日志采集框架-----高可用</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-02-14T19:40:00+08:00">
                2019-02-14
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Flume/" itemprop="url" rel="index">
                    <span itemprop="name">Flume</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h5 id="FLUME高级应用"><a href="#FLUME高级应用" class="headerlink" title="FLUME高级应用"></a>FLUME高级应用</h5><h6 id="案例：高可用Flum-NG配置案例"><a href="#案例：高可用Flum-NG配置案例" class="headerlink" title="案例：高可用Flum-NG配置案例"></a>案例：高可用Flum-NG配置案例</h6><blockquote>
<p>在完成单点的Flume NG搭建后，下面我们搭建一个高可用的Flume NG集群，架构图如下所示：<br><a href="https://imgchr.com/i/kzOPwn" target="_blank" rel="noopener"><img src="https://s2.ax1x.com/2019/03/08/kzOPwn.png" alt="kzOPwn.png"></a></p>
</blockquote>
<blockquote>
<p>图中，我们可以看出，Flume的存储可以支持多种，这里只列举了HDFS和Kafka（如：存储最新的一周日志，并给Storm系统提供实时日志流）。</p>
</blockquote>
<h6 id="角色分配"><a href="#角色分配" class="headerlink" title="角色分配"></a>角色分配</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Flume的Agent和Collector分布如下表所示：</span><br><span class="line">名称　	HOST	角色</span><br><span class="line">Agent1	mini1	Web Server</span><br><span class="line">Agent2	mini2	Web Server</span><br><span class="line">Agent3	mini3	Web Server</span><br><span class="line">Collector1	mini4	AgentMstr1</span><br><span class="line">Collector2	mini5	AgentMstr2</span><br></pre></td></tr></table></figure>
<blockquote>
<p>图中所示，Agent1，Agent2，Agent3数据分别流入到Collector1和Collector2，Flume NG本身提供了Failover机制，可以自动切换和恢复。在上图中，有3个产生日志服务器分布在不同的机房，要把所有的日志都收集到一个集群中存储。下 面我们开发配置Flume NG集群</p>
</blockquote>
<h6 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line">在下面单点Flume中，基本配置都完成了，我们只需要新添加两个配置文件，它们是agent.properties和collector.properties，其配置内容如下所示：</span><br><span class="line">1、agent配置</span><br><span class="line">[root@mini1 apache-flume-1.6.0-bin]# vi conf/agent.properties</span><br><span class="line">#agent1 name</span><br><span class="line">agent1.channels = c1</span><br><span class="line">agent1.sources = r1</span><br><span class="line">agent1.sinks = k1 k2</span><br><span class="line"></span><br><span class="line">#set gruop</span><br><span class="line">agent1.sinkgroups = g1</span><br><span class="line"></span><br><span class="line">#set channel</span><br><span class="line">agent1.channels.c1.type = memory</span><br><span class="line">agent1.channels.c1.capacity = 1000</span><br><span class="line">agent1.channels.c1.transactionCapacity = 100</span><br><span class="line"></span><br><span class="line">agent1.sources.r1.channels = c1</span><br><span class="line">agent1.sources.r1.type = exec</span><br><span class="line">agent1.sources.r1.command = tail -F /root/log/test.log</span><br><span class="line"></span><br><span class="line">agent1.sources.r1.interceptors = i1 i2</span><br><span class="line">agent1.sources.r1.interceptors.i1.type = static</span><br><span class="line">agent1.sources.r1.interceptors.i1.key = Type</span><br><span class="line">agent1.sources.r1.interceptors.i1.value = LOGIN</span><br><span class="line">agent1.sources.r1.interceptors.i2.type = timestamp</span><br><span class="line"></span><br><span class="line"># set sink1</span><br><span class="line">agent1.sinks.k1.channel = c1</span><br><span class="line">agent1.sinks.k1.type = avro</span><br><span class="line">agent1.sinks.k1.hostname = mini2</span><br><span class="line">agent1.sinks.k1.port = 52020</span><br><span class="line"></span><br><span class="line"># set sink2</span><br><span class="line">agent1.sinks.k2.channel = c1</span><br><span class="line">agent1.sinks.k2.type = avro</span><br><span class="line">agent1.sinks.k2.hostname = mini3</span><br><span class="line">agent1.sinks.k2.port = 52020</span><br><span class="line"></span><br><span class="line">#set sink group</span><br><span class="line">agent1.sinkgroups.g1.sinks = k1 k2</span><br><span class="line"></span><br><span class="line">#set failover</span><br><span class="line">agent1.sinkgroups.g1.processor.type = failover</span><br><span class="line">agent1.sinkgroups.g1.processor.priority.k1 = 10</span><br><span class="line">agent1.sinkgroups.g1.processor.priority.k2 = 1</span><br><span class="line">agent1.sinkgroups.g1.processor.maxpenalty = 10000</span><br><span class="line">启动命令：</span><br><span class="line">bin/flume-ng agent -n agent1 -c conf -f conf/agent.properties -Dflume.root.logger=DEBUG,console</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">2、collector配置</span><br><span class="line">[root@mini2 conf]# vi collector.properties </span><br><span class="line">#set Agent name</span><br><span class="line">a1.sources = r1</span><br><span class="line">a1.channels = c1</span><br><span class="line">a1.sinks = k1</span><br><span class="line"></span><br><span class="line">#set channel</span><br><span class="line">a1.channels.c1.type = memory</span><br><span class="line">a1.channels.c1.capacity = 1000</span><br><span class="line">a1.channels.c1.transactionCapacity = 100</span><br><span class="line"></span><br><span class="line"># other node,nna to nns</span><br><span class="line">a1.sources.r1.type = avro</span><br><span class="line">a1.sources.r1.bind = mini2</span><br><span class="line">a1.sources.r1.port = 52020</span><br><span class="line">a1.sources.r1.interceptors = i1</span><br><span class="line">a1.sources.r1.interceptors.i1.type = static</span><br><span class="line">a1.sources.r1.interceptors.i1.key = Collector</span><br><span class="line">a1.sources.r1.interceptors.i1.value = mini2</span><br><span class="line">a1.sources.r1.channels = c1</span><br><span class="line"></span><br><span class="line">#set sink to hdfs</span><br><span class="line">a1.sinks.k1.type=hdfs</span><br><span class="line">a1.sinks.k1.hdfs.path=/home/hdfs/flume/logdfs</span><br><span class="line">a1.sinks.k1.hdfs.fileType=DataStream</span><br><span class="line">a1.sinks.k1.hdfs.writeFormat=TEXT</span><br><span class="line">a1.sinks.k1.hdfs.rollInterval=10</span><br><span class="line">a1.sinks.k1.channel=c1</span><br><span class="line">a1.sinks.k1.hdfs.filePrefix=%Y-%m-%d</span><br><span class="line">在mini3上，需要修改上述配置中的红色字体主机名为mini3</span><br></pre></td></tr></table></figure>
<h6 id="启动命令："><a href="#启动命令：" class="headerlink" title="启动命令："></a>启动命令：</h6><p>bin/flume-ng agent -n a1 -c conf -f conf/collector.properties -Dflume.root.logger=DEBUG,console</p>
<h6 id="FAILOVER测试"><a href="#FAILOVER测试" class="headerlink" title="FAILOVER测试"></a>FAILOVER测试</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">下面我们来测试下Flume NG集群的高可用（故障转移）。场景如下：我们在Agent1节点上传文件，由于我们配置Collector1的权重比Collector2大，所以 Collector1优先采集并上传到存储系统。然后我们kill掉Collector1，此时有Collector2负责日志的采集上传工作，之后，我 们手动恢复Collector1节点的Flume服务，再次在Agent1上次文件，发现Collector1恢复优先级别的采集工作。具体截图如下所 示：</span><br></pre></td></tr></table></figure>
<blockquote>
<p>Collector1优先上传<br><a href="https://imgchr.com/i/kzOelF" target="_blank" rel="noopener"><img src="https://s2.ax1x.com/2019/03/08/kzOelF.png" alt="kzOelF.png"></a><br>HDFS集群中上传的log内容预览<br><a href="https://imgchr.com/i/kzOmy4" target="_blank" rel="noopener"><img src="https://s2.ax1x.com/2019/03/08/kzOmy4.png" alt="kzOmy4.png"></a><br>Collector1宕机，Collector2获取优先上传权限<br><a href="https://imgchr.com/i/kzOnOJ" target="_blank" rel="noopener"><img src="https://s2.ax1x.com/2019/03/08/kzOnOJ.png" alt="kzOnOJ.png"></a><br>重启Collector1服务，Collector1重新获得优先上传的权限</p>
</blockquote>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://blogoflyt.cn/2019/02/13/Flume日志采集框架-采集案例/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Richard">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/gakki.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="积累技术之路">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/02/13/Flume日志采集框架-采集案例/" itemprop="url">Flume日志采集框架-----采集案例</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-02-13T19:33:00+08:00">
                2019-02-13
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Flume/" itemprop="url" rel="index">
                    <span itemprop="name">Flume</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h5 id="采集案例"><a href="#采集案例" class="headerlink" title="采集案例"></a>采集案例</h5><h6 id="1、采集日志目录中的文件到HDFS"><a href="#1、采集日志目录中的文件到HDFS" class="headerlink" title="1、采集日志目录中的文件到HDFS"></a>1、采集日志目录中的文件到HDFS</h6><blockquote>
<p>结构示意图：</p>
</blockquote>
<p><a href="https://imgchr.com/i/kzLssJ" target="_blank" rel="noopener"><img src="https://s2.ax1x.com/2019/03/08/kzLssJ.png" alt="kzLssJ.png"></a><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line">采集需求：某服务器的某特定目录下，会不断产生新的文件，每当有新文件出现，就需要把文件采集到HDFS中去</span><br><span class="line">根据需求，首先定义以下3大要素</span><br><span class="line">数据源组件，即source ——监控文件目录 :  spooldir</span><br><span class="line">spooldir特性：</span><br><span class="line">   1、监视一个目录，只要目录中出现新文件，就会采集文件中的内容</span><br><span class="line">   2、采集完成的文件，会被agent自动添加一个后缀：COMPLETED</span><br><span class="line">   3、所监视的目录中不允许重复出现相同文件名的文件</span><br><span class="line">下沉组件，即sink——HDFS文件系统  :  hdfs sink</span><br><span class="line">通道组件，即channel——可用file channel 也可以用内存channel</span><br><span class="line"></span><br><span class="line">配置文件编写：</span><br><span class="line">#定义三大组件的名称</span><br><span class="line">agent1.sources = source1</span><br><span class="line">agent1.sinks = sink1</span><br><span class="line">agent1.channels = channel1</span><br><span class="line"></span><br><span class="line"># 配置source组件</span><br><span class="line">agent1.sources.source1.type = spooldir</span><br><span class="line">agent1.sources.source1.spoolDir = /home/hadoop/logs/</span><br><span class="line">agent1.sources.source1.fileHeader = false</span><br><span class="line"></span><br><span class="line">#配置拦截器</span><br><span class="line">agent1.sources.source1.interceptors = i1</span><br><span class="line">agent1.sources.source1.interceptors.i1.type = host</span><br><span class="line">agent1.sources.source1.interceptors.i1.hostHeader = hostname</span><br><span class="line"></span><br><span class="line"># 配置sink组件</span><br><span class="line">agent1.sinks.sink1.type = hdfs</span><br><span class="line">agent1.sinks.sink1.hdfs.path =hdfs://hdp-node-01:9000/weblog/flume-collection/%y-%m-%d/%H-%M</span><br><span class="line">agent1.sinks.sink1.hdfs.filePrefix = access_log</span><br><span class="line">agent1.sinks.sink1.hdfs.maxOpenFiles = 5000</span><br><span class="line">agent1.sinks.sink1.hdfs.batchSize= 100</span><br><span class="line">agent1.sinks.sink1.hdfs.fileType = DataStream</span><br><span class="line">agent1.sinks.sink1.hdfs.writeFormat =Text</span><br><span class="line">agent1.sinks.sink1.hdfs.rollSize = 102400</span><br><span class="line">agent1.sinks.sink1.hdfs.rollCount = 1000000</span><br><span class="line">agent1.sinks.sink1.hdfs.rollInterval = 60</span><br><span class="line">#agent1.sinks.sink1.hdfs.round = true</span><br><span class="line">#agent1.sinks.sink1.hdfs.roundValue = 10</span><br><span class="line">#agent1.sinks.sink1.hdfs.roundUnit = minute</span><br><span class="line">agent1.sinks.sink1.hdfs.useLocalTimeStamp = true</span><br><span class="line"># Use a channel which buffers events in memory</span><br><span class="line">agent1.channels.channel1.type = memory</span><br><span class="line">agent1.channels.channel1.keep-alive = 120</span><br><span class="line">agent1.channels.channel1.capacity = 500000</span><br><span class="line">agent1.channels.channel1.transactionCapacity = 600</span><br><span class="line"></span><br><span class="line"># Bind the source and sink to the channel</span><br><span class="line">agent1.sources.source1.channels = channel1</span><br><span class="line">agent1.sinks.sink1.channel = channel1</span><br><span class="line"></span><br><span class="line">Channel参数解释：</span><br><span class="line">capacity：默认该通道中最大的可以存储的event数量</span><br><span class="line">trasactionCapacity：每次最大可以从source中拿到或者送到sink中的event数量</span><br><span class="line">keep-alive：event添加到通道中或者移出的允许时间</span><br><span class="line"></span><br><span class="line">测试阶段，启动flume agent的命令：</span><br><span class="line">bin/flume-ng  agent  -c  ./conf  -f ./dir-hdfs.conf -n  agent1 -Dflume.root.logger=DEBUG,console</span><br><span class="line">-D后面跟的是log4j的参数，用于测试观察</span><br><span class="line"></span><br><span class="line">生产中，启动flume，应该把flume启动在后台：</span><br><span class="line">nohup bin/flume-ng  agent  -c  ./conf  -f ./dir-hdfs.conf -n  agent1 1&gt;/dev/null 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure></p>
<h6 id="采集文件到HDFS"><a href="#采集文件到HDFS" class="headerlink" title="采集文件到HDFS"></a>采集文件到HDFS</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">采集需求：比如业务系统使用log4j生成的日志，日志内容不断增加，需要把追加到日志文件中的数据实时采集到hdfs</span><br><span class="line"></span><br><span class="line">根据需求，首先定义以下3大要素</span><br><span class="line">采集源，即source——监控文件内容更新 :  exec  ‘tail -F file’</span><br><span class="line">下沉目标，即sink——HDFS文件系统  :  hdfs sink</span><br><span class="line">Source和sink之间的传递通道——channel，可用file channel 也可以用 内存channel</span><br><span class="line"></span><br><span class="line">配置文件编写：</span><br><span class="line">agent1.sources = source1</span><br><span class="line">agent1.sinks = sink1</span><br><span class="line">agent1.channels = channel1</span><br><span class="line"></span><br><span class="line"># Describe/configure tail -F source1</span><br><span class="line">agent1.sources.source1.type = exec</span><br><span class="line">agent1.sources.source1.command = tail -F /home/hadoop/logs/access_log</span><br><span class="line">agent1.sources.source1.channels = channel1</span><br><span class="line"></span><br><span class="line">#configure host for source</span><br><span class="line">agent1.sources.source1.interceptors = i1</span><br><span class="line">agent1.sources.source1.interceptors.i1.type = host</span><br><span class="line">agent1.sources.source1.interceptors.i1.hostHeader = hostname</span><br><span class="line"></span><br><span class="line"># Describe sink1</span><br><span class="line">agent1.sinks.sink1.type = hdfs</span><br><span class="line">#a1.sinks.k1.channel = c1</span><br><span class="line">agent1.sinks.sink1.hdfs.path =hdfs://hdp-node-01:9000/weblog/flume-collection/%y-%m-%d/%H-%M</span><br><span class="line">agent1.sinks.sink1.hdfs.filePrefix = access_log</span><br><span class="line">agent1.sinks.sink1.hdfs.maxOpenFiles = 5000</span><br><span class="line">agent1.sinks.sink1.hdfs.batchSize= 100</span><br><span class="line">agent1.sinks.sink1.hdfs.fileType = DataStream</span><br><span class="line">agent1.sinks.sink1.hdfs.writeFormat =Text</span><br><span class="line">agent1.sinks.sink1.hdfs.rollSize = 102400</span><br><span class="line">agent1.sinks.sink1.hdfs.rollCount = 1000000</span><br><span class="line">agent1.sinks.sink1.hdfs.rollInterval = 60</span><br><span class="line">agent1.sinks.sink1.hdfs.round = true</span><br><span class="line">agent1.sinks.sink1.hdfs.roundValue = 10</span><br><span class="line">agent1.sinks.sink1.hdfs.roundUnit = minute</span><br><span class="line">agent1.sinks.sink1.hdfs.useLocalTimeStamp = true</span><br><span class="line"></span><br><span class="line"># Use a channel which buffers events in memory</span><br><span class="line">agent1.channels.channel1.type = memory</span><br><span class="line">agent1.channels.channel1.keep-alive = 120</span><br><span class="line">agent1.channels.channel1.capacity = 500000</span><br><span class="line">agent1.channels.channel1.transactionCapacity = 600</span><br><span class="line"></span><br><span class="line"># Bind the source and sink to the channel</span><br><span class="line">agent1.sources.source1.channels = channel1</span><br><span class="line">agent1.sinks.sink1.channel = channel1</span><br></pre></td></tr></table></figure>
<h6 id="两个agent级联"><a href="#两个agent级联" class="headerlink" title="两个agent级联"></a>两个agent级联</h6><p><a href="https://imgchr.com/i/kzLTLd" target="_blank" rel="noopener"><img src="https://s2.ax1x.com/2019/03/08/kzLTLd.png" alt="kzLTLd.png"></a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">从tail命令获取数据发送到avro端口</span><br><span class="line">另一个节点可配置一个avro源来中继数据，发送外部存储</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">##################</span><br><span class="line"># Name the components on this agent</span><br><span class="line">a1.sources = r1</span><br><span class="line">a1.sinks = k1</span><br><span class="line">a1.channels = c1</span><br><span class="line"></span><br><span class="line"># Describe/configure the source</span><br><span class="line">a1.sources.r1.type = exec</span><br><span class="line">a1.sources.r1.command = tail -F /root/log/access.log</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Describe the sink</span><br><span class="line">a1.sinks.k1.type = avro</span><br><span class="line">a1.sinks.k1.hostname = hdp-05</span><br><span class="line">a1.sinks.k1.port = 4141</span><br><span class="line">a1.sinks.k1.batch-size = 2</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Use a channel which buffers events in memory</span><br><span class="line">a1.channels.c1.type = memory</span><br><span class="line">a1.channels.c1.capacity = 1000</span><br><span class="line">a1.channels.c1.transactionCapacity = 100</span><br><span class="line"></span><br><span class="line"># Bind the source and sink to the channel</span><br><span class="line">a1.sources.r1.channels = c1</span><br><span class="line">a1.sinks.k1.channel = c1</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">从avro端口接收数据，下沉到hdfs</span><br><span class="line">#####</span><br><span class="line">bin/flume-ng agent -c conf -f conf/avro-m-log.conf -n a1 -Dflume.root.logger=INFO,console</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">采集配置文件，avro-hdfs.conf</span><br><span class="line"></span><br><span class="line"># Name the components on this agent</span><br><span class="line">a1.sources = r1</span><br><span class="line">a1.sinks = k1</span><br><span class="line">a1.channels = c1</span><br><span class="line"></span><br><span class="line"># Describe/configure the source</span><br><span class="line">##source中的avro组件是一个接收者服务</span><br><span class="line">a1.sources.r1.type = avro</span><br><span class="line">a1.sources.r1.bind = hdp-05</span><br><span class="line">a1.sources.r1.port = 4141</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Describe the sink</span><br><span class="line">a1.sinks.k1.type = hdfs</span><br><span class="line">a1.sinks.k1.hdfs.path = /flume/taildata/%y-%m-%d/</span><br><span class="line">a1.sinks.k1.hdfs.filePrefix = tail-</span><br><span class="line">a1.sinks.k1.hdfs.round = true</span><br><span class="line">a1.sinks.k1.hdfs.roundValue = 24</span><br><span class="line">a1.sinks.k1.hdfs.roundUnit = hour</span><br><span class="line">a1.sinks.k1.hdfs.rollInterval = 0</span><br><span class="line">a1.sinks.k1.hdfs.rollSize = 0</span><br><span class="line">a1.sinks.k1.hdfs.rollCount = 50</span><br><span class="line">a1.sinks.k1.hdfs.batchSize = 10</span><br><span class="line">a1.sinks.k1.hdfs.useLocalTimeStamp = true</span><br><span class="line">#生成的文件类型，默认是Sequencefile，可用DataStream，则为普通文本</span><br><span class="line">a1.sinks.k1.hdfs.fileType = DataStream</span><br><span class="line"></span><br><span class="line"># Use a channel which buffers events in memory</span><br><span class="line">a1.channels.c1.type = memory</span><br><span class="line">a1.channels.c1.capacity = 1000</span><br><span class="line">a1.channels.c1.transactionCapacity = 100</span><br><span class="line"></span><br><span class="line"># Bind the source and sink to the channel</span><br><span class="line">a1.sources.r1.channels = c1</span><br><span class="line">a1.sinks.k1.channel = c1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">发送数据：</span><br><span class="line">$ bin/flume-ng avro-client -H localhost -p 4141 -F /usr/logs/log.10</span><br></pre></td></tr></table></figure>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://blogoflyt.cn/2019/02/13/Flume日志采集框架-安装配置/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Richard">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/gakki.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="积累技术之路">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/02/13/Flume日志采集框架-安装配置/" itemprop="url">Flume日志采集框架-----安装配置</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-02-13T19:23:00+08:00">
                2019-02-13
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Flume/" itemprop="url" rel="index">
                    <span itemprop="name">Flume</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h5 id="Flume介绍"><a href="#Flume介绍" class="headerlink" title="Flume介绍"></a>Flume介绍</h5><h6 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Flume是一个分布式、可靠、和高可用的海量日志采集、聚合和传输的系统。</span><br><span class="line">Flume可以采集文件，socket数据包、文件、文件夹、kafka等各种形式源数据，又可以将采集到的数据(下沉sink)输出到HDFS、hbase、hive、kafka等众多外部存储系统中</span><br><span class="line">一般的采集需求，通过对flume的简单配置即可实现</span><br><span class="line">Flume针对特殊场景也具备良好的自定义扩展能力，</span><br><span class="line">因此，flume可以适用于大部分的日常数据采集场景</span><br></pre></td></tr></table></figure>
<h6 id="运行机制"><a href="#运行机制" class="headerlink" title="运行机制"></a>运行机制</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">1、Flume分布式系统中最核心的角色是agent，flume采集系统就是由一个个agent所连接起来形成</span><br><span class="line">2、每一个agent相当于一个数据传递员[Source 到 Channel 到 Sink之间传递数据的形式是Event事件；Event事件是一个数据流单元。</span><br><span class="line">]，内部有三个组件：</span><br><span class="line">a)Source：采集组件，用于跟数据源对接，以获取数据</span><br><span class="line">b)Sink：下沉组件，用于往下一级agent传递数据或者往最终存储系统传递数据</span><br><span class="line">c)Channel：传输通道组件，用于从source将数据传递到sink</span><br></pre></td></tr></table></figure>
<blockquote>
<p>Source 到 Channel 到 Sink之间传递数据的形式是Event事件；Event事件是一个数据流单元。</p>
</blockquote>
<p><a href="https://imgchr.com/i/kzLVrd" target="_blank" rel="noopener"><img src="https://s2.ax1x.com/2019/03/08/kzLVrd.png" alt="kzLVrd.png"></a></p>
<h5 id="Flume采集系统结构图"><a href="#Flume采集系统结构图" class="headerlink" title="Flume采集系统结构图"></a>Flume采集系统结构图</h5><h6 id="1-简单结构"><a href="#1-简单结构" class="headerlink" title="1. 简单结构"></a>1. 简单结构</h6><blockquote>
<p>单个agent采集数据<br><a href="https://imgchr.com/i/kzLnat" target="_blank" rel="noopener"><img src="https://s2.ax1x.com/2019/03/08/kzLnat.png" alt="kzLnat.png"></a></p>
</blockquote>
<h6 id="复杂结构"><a href="#复杂结构" class="headerlink" title="复杂结构"></a>复杂结构</h6><blockquote>
<p>多级agent之间串联<br><a href="https://imgchr.com/i/kzLMPf" target="_blank" rel="noopener"><img src="https://s2.ax1x.com/2019/03/08/kzLMPf.png" alt="kzLMPf.png"></a></p>
</blockquote>
<h5 id="Flume实战案例"><a href="#Flume实战案例" class="headerlink" title="Flume实战案例"></a>Flume实战案例</h5><h6 id="1-2-1-Flume的安装部署"><a href="#1-2-1-Flume的安装部署" class="headerlink" title="1.2.1 Flume的安装部署"></a>1.2.1 Flume的安装部署</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">1、Flume的安装非常简单，只需要解压即可，当然，前提是已有hadoop环境</span><br><span class="line">上传安装包到数据源所在节点上</span><br><span class="line">然后解压  tar -zxvf apache-flume-1.6.0-bin.tar.gz</span><br><span class="line">然后进入flume的目录，修改conf下的flume-env.sh，在里面配置JAVA_HOME</span><br><span class="line"></span><br><span class="line">2、根据数据采集的需求配置采集方案，描述在配置文件中(文件名可任意自定义)</span><br><span class="line">3、指定采集方案配置文件，在相应的节点上启动flume agent</span><br><span class="line"></span><br><span class="line">先用一个最简单的例子来测试一下程序环境是否正常</span><br></pre></td></tr></table></figure>
<p><a href="https://imgchr.com/i/kzLlRS" target="_blank" rel="noopener"><img src="https://s2.ax1x.com/2019/03/08/kzLlRS.png" alt="kzLlRS.png"></a><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">1、先在flume的conf目录下新建一个配置文件（采集方案）</span><br><span class="line">vi   netcat-logger.properties</span><br><span class="line"># 定义这个agent中各组件的名字</span><br><span class="line">a1.sources = r1</span><br><span class="line">a1.sinks = k1</span><br><span class="line">a1.channels = c1</span><br><span class="line"></span><br><span class="line"># 描述和配置source组件：r1</span><br><span class="line">a1.sources.r1.type = netcat</span><br><span class="line">a1.sources.r1.bind = localhost</span><br><span class="line">a1.sources.r1.port = 44444</span><br><span class="line"></span><br><span class="line"># 描述和配置sink组件：k1</span><br><span class="line">a1.sinks.k1.type = logger</span><br><span class="line"></span><br><span class="line"># 描述和配置channel组件，此处使用是内存缓存的方式</span><br><span class="line">a1.channels.c1.type = memory</span><br><span class="line">a1.channels.c1.capacity = 1000</span><br><span class="line">a1.channels.c1.transactionCapacity = 100</span><br><span class="line"></span><br><span class="line"># 描述和配置source  channel   sink之间的连接关系</span><br><span class="line">a1.sources.r1.channels = c1</span><br><span class="line">a1.sinks.k1.channel = c1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">2、启动agent去采集数据</span><br><span class="line">bin/flume-ng agent -c conf -f conf/netcat-logger.conf -n a1  -Dflume.root.logger=INFO,console</span><br><span class="line">-c conf   指定flume自身的配置文件所在目录</span><br><span class="line">-f conf/netcat-logger.con  指定我们所描述的采集方案</span><br><span class="line">-n a1  指定我们这个agent的名字</span><br><span class="line"></span><br><span class="line">3、测试</span><br><span class="line">先要往agent的source所监听的端口上发送数据，让agent有数据可采</span><br><span class="line">随便在一个能跟agent节点联网的机器上</span><br><span class="line">telnet anget-hostname  port   （telnet localhost 44444）</span><br></pre></td></tr></table></figure></p>
<p><a href="https://imgchr.com/i/kzLNaq" target="_blank" rel="noopener"><img src="https://s2.ax1x.com/2019/03/08/kzLNaq.png" alt="kzLNaq.png"></a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://blogoflyt.cn/2019/02/10/HBASE运行原理/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Richard">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/gakki.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="积累技术之路">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/02/10/HBASE运行原理/" itemprop="url">HBASE运行原理</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-02-10T21:04:00+08:00">
                2019-02-10
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/HBASE/" itemprop="url" rel="index">
                    <span itemprop="name">HBASE</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h5 id="组件结构图"><a href="#组件结构图" class="headerlink" title="组件结构图"></a>组件结构图</h5><p><a href="https://imgchr.com/i/kxR4LF" target="_blank" rel="noopener"><img src="https://s2.ax1x.com/2019/03/07/kxR4LF.png" alt="kxR4LF.png"></a></p>
<h6 id="MASTER职责"><a href="#MASTER职责" class="headerlink" title="MASTER职责"></a>MASTER职责</h6><ol>
<li>管理HRegionServer，实现其负载均衡。<br>管理和分配HRegion，比如在HRegion split时分配新的HRegion；在HRegionServer退出时迁移其负责的HRegion到其他HRegionServer上。</li>
<li>Admin职能<br>创建、删除、修改Table的定义。实现DDL操作（namespace和table的增删改，column familiy的增删改等）。<br>管理namespace和table的元数据（实际存储在HDFS上）。<br>权限控制（ACL）。<br>监控集群中所有HRegionServer的状态(通过Heartbeat和监听ZooKeeper中的状态)。</li>
</ol>
<h6 id="REGION-SERVER职责"><a href="#REGION-SERVER职责" class="headerlink" title="REGION SERVER职责"></a>REGION SERVER职责</h6><ol>
<li>管理自己所负责的region数据的读写。</li>
<li>读写HDFS，管理Table中的数据。</li>
<li>Client直接通过HRegionServer读写数据（从HMaster中获取元数据，找到RowKey所在的HRegion/HRegionServer后）。</li>
</ol>
<h6 id="Zookeeper集群所起作用"><a href="#Zookeeper集群所起作用" class="headerlink" title="Zookeeper集群所起作用"></a>Zookeeper集群所起作用</h6><ol>
<li>存放整个HBase集群的元数据以及集群的状态信息。</li>
<li>实现HMaster主从节点的failover。<blockquote>
<p>注： HMaster通过监听ZooKeeper中的Ephemeral节点(默认：/hbase/rs/*)来监控HRegionServer的加入和宕机。<br>在第一个HMaster连接到ZooKeeper时会创建Ephemeral节点(默认：/hbasae/master)来表示Active的HMaster，其后加进来的HMaster则监听该Ephemeral节点<br>如果当前Active的HMaster宕机，则该节点消失，因而其他HMaster得到通知，而将自身转换成Active的HMaster，在变为Active的HMaster之前，它会在/hbase/masters/下创建自己的Ephemeral节点。</p>
</blockquote>
</li>
</ol>
<h5 id="HBASE读写数据流程"><a href="#HBASE读写数据流程" class="headerlink" title="HBASE读写数据流程"></a>HBASE读写数据流程</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">1. 在HBase 0.96以前，HBase有两个特殊的Table：-ROOT-和.META. 用来记录用户表的rowkey范围所在的的regionserver服务器；因而客户端读写数据时需要通过3次寻址请求来对数据所在的regionserver进行定位，效率低下；</span><br></pre></td></tr></table></figure>
<p><a href="https://imgchr.com/i/kxRTo9" target="_blank" rel="noopener"><img src="https://s2.ax1x.com/2019/03/07/kxRTo9.jpg" alt="kxRTo9.jpg"></a><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">2. 而在HBase 0.96以后去掉了-ROOT- Table，只剩下这个特殊的目录表叫做Meta Table(hbase:meta)，它存储了集群中所有用户HRegion的位置信息，而ZooKeeper的节点中(/hbase/meta-region-server)存储的则直接是这个Meta Table的位置，并且这个Meta Table如以前的-ROOT- Table一样是不可split的。这样，客户端在第一次访问用户Table的流程就变成了：</span><br><span class="line">①　从ZooKeeper(/hbase/meta-region-server)中获取hbase:meta的位置（HRegionServer的位置），缓存该位置信息。</span><br><span class="line">②　从HRegionServer中查询用户Table对应请求的RowKey所在的HRegionServer，缓存该位置信息。</span><br><span class="line">③　从查询到HRegionServer中读取Row。</span><br><span class="line">注：客户会缓存这些位置信息，然而第二步它只是缓存当前RowKey对应的HRegion的位置，因而如果下一个要查的RowKey不在同一个HRegion中，则需要继续查询hbase:meta所在的HRegion，然而随着时间的推移，客户端缓存的位置信息越来越多，以至于不需要再次查找hbase:meta Table的信息，除非某个HRegion因为宕机或Split被移动，此时需要重新查询并且更新缓存。</span><br></pre></td></tr></table></figure></p>
<h6 id="hbase-meta表"><a href="#hbase-meta表" class="headerlink" title="hbase:meta表"></a>hbase:meta表</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">hbase:meta表存储了所有用户HRegion的位置信息：</span><br><span class="line">Rowkey：tableName,regionStartKey,regionId,replicaId等；</span><br><span class="line">info列族：这个列族包含三个列，他们分别是：</span><br><span class="line">info:regioninfo列：</span><br><span class="line">regionId,tableName,startKey,endKey,offline,split,replicaId；</span><br><span class="line">info:server列：HRegionServer对应的server:port；</span><br><span class="line">info:serverstartcode列：HRegionServer的启动时间戳。</span><br></pre></td></tr></table></figure>
<p><a href="https://imgchr.com/i/kxRLz6" target="_blank" rel="noopener"><img src="https://s2.ax1x.com/2019/03/07/kxRLz6.png" alt="kxRLz6.png"></a></p>
<h6 id="REGION-SERVER内部机制"><a href="#REGION-SERVER内部机制" class="headerlink" title="REGION SERVER内部机制"></a>REGION SERVER内部机制</h6><p><a href="https://imgchr.com/i/kxRvLD" target="_blank" rel="noopener"><img src="https://s2.ax1x.com/2019/03/07/kxRvLD.png" alt="kxRvLD.png"></a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">WAL即Write Ahead Log，在早期版本中称为HLog，它是HDFS上的一个文件，如其名字所表示的，所有写操作都会先保证将数据写入这个Log文件后，才会真正更新MemStore，最后写入HFile中。WAL文件存储在/hbase/WALs/$&#123;HRegionServer_Name&#125;的目录中</span><br><span class="line"></span><br><span class="line">BlockCache是一个读缓存，即“引用局部性”原理（也应用于CPU，分空间局部性和时间局部性，空间局部性是指CPU在某一时刻需要某个数据，那么有很大的概率在一下时刻它需要的数据在其附近；时间局部性是指某个数据在被访问过一次后，它有很大的概率在不久的将来会被再次的访问），将数据预读取到内存中，以提升读的性能。</span><br><span class="line"></span><br><span class="line">HRegion是一个Table中的一个Region在一个HRegionServer中的表达。一个Table可以有一个或多个Region，他们可以在一个相同的HRegionServer上，也可以分布在不同的HRegionServer上，一个HRegionServer可以有多个HRegion，他们分别属于不同的Table。HRegion由多个Store(HStore)构成，每个HStore对应了一个Table在这个HRegion中的一个Column Family，即每个Column Family就是一个集中的存储单元，因而最好将具有相近IO特性的Column存储在一个Column Family，以实现高效读取(数据局部性原理，可以提高缓存的命中率)。HStore是HBase中存储的核心，它实现了读写HDFS功能，一个HStore由一个MemStore 和0个或多个StoreFile组成。</span><br><span class="line"></span><br><span class="line">MemStore是一个写缓存(In Memory Sorted Buffer)，所有数据的写在完成WAL日志写后，会 写入MemStore中，由MemStore根据一定的算法将数据Flush到地层HDFS文件中(HFile)，通常每个HRegion中的每个 Column Family有一个自己的MemStore。</span><br><span class="line"></span><br><span class="line">HFile(StoreFile) 用于存储HBase的数据(Cell/KeyValue)。在HFile中的数据是按RowKey、Column Family、Column排序，对相同的Cell(即这三个值都一样)，则按timestamp倒序排列。</span><br><span class="line"></span><br><span class="line">FLUSH详述</span><br><span class="line"></span><br><span class="line">①　每一次Put/Delete请求都是先写入到MemStore中，当MemStore满后会Flush成一个新的StoreFile(底层实现是HFile)，即一个HStore(Column Family)可以有0个或多个StoreFile(HFile)。</span><br><span class="line"></span><br><span class="line">②　当一个HRegion中的所有MemStore的大小总和超过了hbase.hregion.memstore.flush.size的大小，默认128MB。此时当前的HRegion中所有的MemStore会Flush到HDFS中。</span><br><span class="line"></span><br><span class="line">③　当全局MemStore的大小超过了hbase.regionserver.global.memstore.upperLimit的大小，默认40％的内存使用量。此时当前HRegionServer中所有HRegion中的MemStore都会Flush到HDFS中，Flush顺序是MemStore大小的倒序（一个HRegion中所有MemStore总和作为该HRegion的MemStore的大小还是选取最大的MemStore作为参考？有待考证），直到总体的MemStore使用量低于hbase.regionserver.global.memstore.lowerLimit，默认38%的内存使用量。</span><br><span class="line"></span><br><span class="line">④　当前HRegionServer中WAL的大小超过了</span><br><span class="line">hbase.regionserver.hlog.blocksize * hbase.regionserver.max.logs</span><br><span class="line">的数量，当前HRegionServer中所有HRegion中的MemStore都会Flush到HDFS中，</span><br><span class="line">Flush使用时间顺序，最早的MemStore先Flush直到WAL的数量少于</span><br><span class="line">hbase.regionserver.hlog.blocksize * hbase.regionserver.max.logs</span><br><span class="line">这里说这两个相乘的默认大小是2GB，查代码，hbase.regionserver.max.logs默认值是32，而hbase.regionserver.hlog.blocksize默认是32MB。但不管怎么样，因为这个大小超过限制引起的Flush不是一件好事，可能引起长时间的延迟</span><br></pre></td></tr></table></figure>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://blogoflyt.cn/2019/02/08/HBASE客户端操作/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Richard">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/gakki.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="积累技术之路">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/02/08/HBASE客户端操作/" itemprop="url">HBASE客户端操作</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-02-08T20:18:00+08:00">
                2019-02-08
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/HBASE/" itemprop="url" rel="index">
                    <span itemprop="name">HBASE</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h5 id="HBASE表模型"><a href="#HBASE表模型" class="headerlink" title="HBASE表模型"></a>HBASE表模型</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hbase的表模型跟mysql之类的关系型数据库的表模型差别巨大</span><br><span class="line">hbase的表模型中有：行的概念；但没有字段的概念</span><br><span class="line">行中存的都是key-value对，每行中的key-value对中的key可以是各种各样，每行中的key-value对的数量也可以是各种各样</span><br></pre></td></tr></table></figure>
<h6 id="hbase表模型的要点："><a href="#hbase表模型的要点：" class="headerlink" title="hbase表模型的要点："></a>hbase表模型的要点：</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">1、一个表，有表名</span><br><span class="line">2、一个表可以分为多个列族（不同列族的数据会存储在不同文件中）</span><br><span class="line">3、表中的每一行有一个“行键rowkey”，而且行键在表中不能重复</span><br><span class="line">4、表中的每一对kv数据称作一个cell</span><br><span class="line">5、hbase可以对数据存储多个历史版本（历史版本数量可配置）</span><br><span class="line">6、整张表由于数据量过大，会被横向切分成若干个region（用rowkey范围标识），不同region的数据也存储在不同文件中</span><br><span class="line"></span><br><span class="line">7、hbase会对插入的数据按顺序存储：</span><br><span class="line">要点一：首先会按行键排序</span><br><span class="line">要点二：同一行里面的kv会按列族排序，再按k排序</span><br></pre></td></tr></table></figure>
<h6 id="hbase的表中能存储什么数据类型"><a href="#hbase的表中能存储什么数据类型" class="headerlink" title="hbase的表中能存储什么数据类型"></a>hbase的表中能存储什么数据类型</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hbase中只支持byte[] </span><br><span class="line">此处的byte[] 包括了： rowkey,key,value,列族名,表名</span><br></pre></td></tr></table></figure>
<h6 id="hbase命令行客户端操作"><a href="#hbase命令行客户端操作" class="headerlink" title="hbase命令行客户端操作"></a>hbase命令行客户端操作</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">建表：</span><br><span class="line">create &apos;t_user_info&apos;,&apos;base_info&apos;,&apos;extra_info&apos;</span><br><span class="line">         表名      列族名   列族名</span><br><span class="line"></span><br><span class="line">插入数据：</span><br><span class="line">hbase(main):011:0&gt; put &apos;t_user_info&apos;,&apos;001&apos;,&apos;base_info:username&apos;,&apos;zhangsan&apos;</span><br><span class="line">0 row(s) in 0.2420 seconds</span><br><span class="line"></span><br><span class="line">hbase(main):012:0&gt; put &apos;t_user_info&apos;,&apos;001&apos;,&apos;base_info:age&apos;,&apos;18&apos;</span><br><span class="line">0 row(s) in 0.0140 seconds</span><br><span class="line"></span><br><span class="line">hbase(main):013:0&gt; put &apos;t_user_info&apos;,&apos;001&apos;,&apos;base_info:sex&apos;,&apos;female&apos;</span><br><span class="line">0 row(s) in 0.0070 seconds</span><br><span class="line"></span><br><span class="line">hbase(main):014:0&gt; put &apos;t_user_info&apos;,&apos;001&apos;,&apos;extra_info:career&apos;,&apos;it&apos;</span><br><span class="line">0 row(s) in 0.0090 seconds</span><br><span class="line"></span><br><span class="line">hbase(main):015:0&gt; put &apos;t_user_info&apos;,&apos;002&apos;,&apos;extra_info:career&apos;,&apos;actoress&apos;</span><br><span class="line">0 row(s) in 0.0090 seconds</span><br><span class="line"></span><br><span class="line">hbase(main):016:0&gt; put &apos;t_user_info&apos;,&apos;002&apos;,&apos;base_info:username&apos;,&apos;liuyifei&apos;</span><br><span class="line">0 row(s) in 0.0060 seconds</span><br></pre></td></tr></table></figure>
<h6 id="查询数据方式一：scan-扫描"><a href="#查询数据方式一：scan-扫描" class="headerlink" title="查询数据方式一：scan 扫描"></a>查询数据方式一：scan 扫描</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">hbase(main):017:0&gt; scan &apos;t_user_info&apos;</span><br><span class="line">ROW                               COLUMN+CELL                                                                                     </span><br><span class="line"> 001                              column=base_info:age, timestamp=1496567924507, value=18                                         </span><br><span class="line"> 001                              column=base_info:sex, timestamp=1496567934669, value=female                                     </span><br><span class="line"> 001                              column=base_info:username, timestamp=1496567889554, value=zhangsan                              </span><br><span class="line"> 001                              column=extra_info:career, timestamp=1496567963992, value=it                                     </span><br><span class="line"> 002                              column=base_info:username, timestamp=1496568034187, value=liuyifei                              </span><br><span class="line"> 002                              column=extra_info:career, timestamp=1496568008631, value=actoress                               </span><br><span class="line">2 row(s) in 0.0420 seconds</span><br></pre></td></tr></table></figure>
<h6 id="查询数据方式二：get-单行数据"><a href="#查询数据方式二：get-单行数据" class="headerlink" title="查询数据方式二：get 单行数据"></a>查询数据方式二：get 单行数据</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">hbase(main):020:0&gt; get &apos;t_user_info&apos;,&apos;001&apos;</span><br><span class="line">COLUMN                            CELL                                                                                            </span><br><span class="line"> base_info:age                    timestamp=1496568160192, value=19                                                               </span><br><span class="line"> base_info:sex                    timestamp=1496567934669, value=female                                                           </span><br><span class="line"> base_info:username               timestamp=1496567889554, value=zhangsan                                                         </span><br><span class="line"> extra_info:career                timestamp=1496567963992, value=it                                                               </span><br><span class="line">4 row(s) in 0.0770 seconds</span><br></pre></td></tr></table></figure>
<h6 id="删除一个kv数据"><a href="#删除一个kv数据" class="headerlink" title="删除一个kv数据"></a>删除一个kv数据</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">删除一个kv数据</span><br><span class="line">hbase(main):021:0&gt; delete &apos;t_user_info&apos;,&apos;001&apos;,&apos;base_info:sex&apos;</span><br><span class="line">0 row(s) in 0.0390 seconds</span><br><span class="line"></span><br><span class="line">删除整行数据：</span><br><span class="line">hbase(main):024:0&gt; deleteall &apos;t_user_info&apos;,&apos;001&apos;</span><br><span class="line">0 row(s) in 0.0090 seconds</span><br><span class="line"></span><br><span class="line">hbase(main):025:0&gt; get &apos;t_user_info&apos;,&apos;001&apos;</span><br><span class="line">COLUMN                            CELL                                                                                         </span><br><span class="line">0 row(s) in 0.0110 seconds</span><br></pre></td></tr></table></figure>
<h6 id="删除整个表："><a href="#删除整个表：" class="headerlink" title="删除整个表："></a>删除整个表：</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">hbase(main):028:0&gt; disable &apos;t_user_info&apos;</span><br><span class="line">0 row(s) in 2.3640 seconds</span><br><span class="line"></span><br><span class="line">hbase(main):029:0&gt; drop &apos;t_user_info&apos;</span><br><span class="line">0 row(s) in 1.2950 seconds</span><br><span class="line"></span><br><span class="line">hbase(main):030:0&gt; list</span><br><span class="line">TABLE                                                                                                                             </span><br><span class="line">0 row(s) in 0.0130 seconds</span><br></pre></td></tr></table></figure>
<h6 id="Hbase重要特性–排序特性（行键）"><a href="#Hbase重要特性–排序特性（行键）" class="headerlink" title="Hbase重要特性–排序特性（行键）"></a>Hbase重要特性–排序特性（行键）</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">插入到hbase中去的数据，hbase会自动排序存储：</span><br><span class="line">排序规则：  首先看行键，然后看列族名，然后看列（key）名； 按字典顺序</span><br><span class="line"></span><br><span class="line">Hbase的这个特性跟查询效率有极大的关系</span><br><span class="line">比如：一张用来存储用户信息的表，有名字，户籍，年龄，职业....等信息</span><br><span class="line">然后，在业务系统中经常需要：</span><br><span class="line">查询某个省的所有用户</span><br><span class="line">经常需要查询某个省的指定姓的所有用户</span><br><span class="line"></span><br><span class="line">思路：如果能将相同省的用户在hbase的存储文件中连续存储，并且能将相同省中相同姓的用户连续存储，那么，上述两个查询需求的效率就会提高！！！</span><br><span class="line"></span><br><span class="line">做法：将查询条件拼到rowkey内</span><br></pre></td></tr></table></figure>
<h5 id="HBASE客户端API操作"><a href="#HBASE客户端API操作" class="headerlink" title="HBASE客户端API操作"></a>HBASE客户端API操作</h5><h6 id="DDL操作"><a href="#DDL操作" class="headerlink" title="DDL操作"></a>DDL操作</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">1、创建一个连接</span><br><span class="line">Connection conn = ConnectionFactory.createConnection(conf);</span><br><span class="line">2、拿到一个DDL操作器：表管理器admin</span><br><span class="line">Admin admin = conn.getAdmin();</span><br><span class="line">3、用表管理器的api去建表、删表、修改表定义</span><br><span class="line">admin.createTable(HTableDescriptor descriptor);</span><br></pre></td></tr></table></figure>
<h6 id="DML操作"><a href="#DML操作" class="headerlink" title="DML操作"></a>DML操作</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br></pre></td><td class="code"><pre><span class="line">package clientDemo;</span><br><span class="line"></span><br><span class="line">import java.util.ArrayList;</span><br><span class="line">import java.util.Iterator;</span><br><span class="line"></span><br><span class="line">import org.apache.hadoop.conf.Configuration;</span><br><span class="line">import org.apache.hadoop.hbase.Cell;</span><br><span class="line">import org.apache.hadoop.hbase.CellScanner;</span><br><span class="line">import org.apache.hadoop.hbase.HBaseConfiguration;</span><br><span class="line">import org.apache.hadoop.hbase.TableName;</span><br><span class="line">import org.apache.hadoop.hbase.client.Connection;</span><br><span class="line">import org.apache.hadoop.hbase.client.ConnectionFactory;</span><br><span class="line">import org.apache.hadoop.hbase.client.Delete;</span><br><span class="line">import org.apache.hadoop.hbase.client.Get;</span><br><span class="line">import org.apache.hadoop.hbase.client.Put;</span><br><span class="line">import org.apache.hadoop.hbase.client.Result;</span><br><span class="line">import org.apache.hadoop.hbase.client.ResultScanner;</span><br><span class="line">import org.apache.hadoop.hbase.client.Scan;</span><br><span class="line">import org.apache.hadoop.hbase.client.Table;</span><br><span class="line">import org.apache.hadoop.hbase.util.Bytes;</span><br><span class="line">import org.junit.Before;</span><br><span class="line">import org.junit.Test;</span><br><span class="line"></span><br><span class="line">public class HbaseClientDML &#123;</span><br><span class="line"></span><br><span class="line">	Configuration conf=null;</span><br><span class="line">	Connection conn=null;</span><br><span class="line">	</span><br><span class="line">	@Before</span><br><span class="line">	public void getConn() throws Exception&#123;</span><br><span class="line">		Configuration conf = HBaseConfiguration.create();</span><br><span class="line">		conf.set(&quot;hbase.zookeeper.quorum&quot;, &quot;namenode:2181,datanode1:2181,datanode2:2181,datanode3:2181&quot;);</span><br><span class="line"></span><br><span class="line">		conn = ConnectionFactory.createConnection(conf);</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	/*</span><br><span class="line">	 * 增、改（一样的，改就是put来覆盖）</span><br><span class="line">	 */</span><br><span class="line">	</span><br><span class="line">	@Test</span><br><span class="line">	public void testPut() throws Exception&#123;</span><br><span class="line">		</span><br><span class="line">		//获取一个操作指定表的table对象，进行DML操作</span><br><span class="line">		Table table = conn.getTable(TableName.valueOf(&quot;user_info&quot;));</span><br><span class="line">		</span><br><span class="line">		//构造要插入的数据为一个Put类型的对象(一个put对象只能对应一个rowkey)的对象</span><br><span class="line">		Put put1 = new Put(Bytes.toBytes(&quot;001&quot;));</span><br><span class="line">		//args: 列族，key，value</span><br><span class="line">		put1.addColumn(Bytes.toBytes(&quot;base_info&quot;), Bytes.toBytes(&quot;username&quot;), Bytes.toBytes(&quot;zhangsan&quot;));</span><br><span class="line">		put1.addColumn(Bytes.toBytes(&quot;base_info&quot;), Bytes.toBytes(&quot;age&quot;), Bytes.toBytes(&quot;18&quot;));</span><br><span class="line">		put1.addColumn(Bytes.toBytes(&quot;extra_info&quot;), Bytes.toBytes(&quot;home&quot;), Bytes.toBytes(&quot;beijing&quot;));</span><br><span class="line"></span><br><span class="line">		</span><br><span class="line">		Put put2 = new Put(Bytes.toBytes(&quot;002&quot;));</span><br><span class="line">		//args: 列族，key，value</span><br><span class="line">		put2.addColumn(Bytes.toBytes(&quot;base_info&quot;), Bytes.toBytes(&quot;username&quot;), Bytes.toBytes(&quot;lisi&quot;));</span><br><span class="line">		put2.addColumn(Bytes.toBytes(&quot;base_info&quot;), Bytes.toBytes(&quot;age&quot;), Bytes.toBytes(&quot;28&quot;));</span><br><span class="line">		put2.addColumn(Bytes.toBytes(&quot;extra_info&quot;), Bytes.toBytes(&quot;home&quot;), Bytes.toBytes(&quot;tianjing&quot;));</span><br><span class="line">		</span><br><span class="line">		//插进去</span><br><span class="line">//		table.put(put);</span><br><span class="line">		</span><br><span class="line">		ArrayList&lt;Put&gt; puts = new ArrayList&lt;&gt;();</span><br><span class="line">		</span><br><span class="line">		puts.add(put1);</span><br><span class="line">		puts.add(put2);</span><br><span class="line">		</span><br><span class="line">		table.put(puts);</span><br><span class="line">		</span><br><span class="line">		conn.close();</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	</span><br><span class="line">	/*</span><br><span class="line">	 * 删</span><br><span class="line">	 */</span><br><span class="line">	</span><br><span class="line">	@Test</span><br><span class="line">	public void testRm() throws Exception &#123;</span><br><span class="line">		 Table table = conn.getTable(TableName.valueOf(&quot;user_info&quot;));</span><br><span class="line">		 Delete delete1 = new Delete(Bytes.toBytes(&quot;001&quot;));</span><br><span class="line">		 Delete delete2 = new Delete(Bytes.toBytes(&quot;002&quot;));</span><br><span class="line">		 delete2.addColumn(Bytes.toBytes(&quot;extra_info&quot;), Bytes.toBytes(&quot;home&quot;));</span><br><span class="line">		 </span><br><span class="line">		 ArrayList&lt;Delete&gt; dels = new ArrayList&lt;&gt;();</span><br><span class="line">		 </span><br><span class="line">		 dels.add(delete1);</span><br><span class="line">		 dels.add(delete2);</span><br><span class="line">		 </span><br><span class="line">		 </span><br><span class="line">		 table.delete(dels);</span><br><span class="line">		 </span><br><span class="line">		 table.close();</span><br><span class="line">		 conn.close();</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	/*</span><br><span class="line">	 * 查</span><br><span class="line">	 */</span><br><span class="line">	@Test</span><br><span class="line">	public void testGet()  throws Exception&#123;</span><br><span class="line">		</span><br><span class="line">		Table table = conn.getTable(TableName.valueOf(&quot;user_info&quot;));</span><br><span class="line">		</span><br><span class="line">		Get get = new Get(&quot;002&quot;.getBytes());</span><br><span class="line">		</span><br><span class="line">		Result result = table.get(get);</span><br><span class="line">		CellScanner cellScanner = result.cellScanner();</span><br><span class="line">		</span><br><span class="line">		//遍历整行所有的key value</span><br><span class="line">		while(cellScanner.advance()) &#123;</span><br><span class="line">			Cell cell = cellScanner.current();</span><br><span class="line">			byte[] rowArray = cell.getRowArray();</span><br><span class="line">			byte[] familyArray = cell.getFamilyArray(); //列族名的字节数组</span><br><span class="line">			byte[] qualifierArray = cell.getQualifierArray(); //列名的字节数组</span><br><span class="line">			byte[] valueArray = cell.getValueArray(); //拿到value的字节数组</span><br><span class="line">			System.out.println(&quot;行键&quot;+new String(rowArray,cell.getRowOffset(),cell.getRowLength()));</span><br><span class="line">			System.out.println(&quot;列族名&quot;+new String(familyArray,cell.getFamilyOffset(),cell.getFamilyLength()));</span><br><span class="line">			System.out.println(&quot;列名&quot;+new String(qualifierArray,cell.getQualifierOffset(),cell.getQualifierLength()));</span><br><span class="line">			System.out.println(&quot;value:&quot;+new String(valueArray,cell.getValueOffset(),cell.getValueLength()));</span><br><span class="line">			</span><br><span class="line">		&#125;</span><br><span class="line">		</span><br><span class="line">		//直接从结果中取用户指定的key-value</span><br><span class="line">		byte[] value = result.getValue(&quot;base_info&quot;.getBytes(), &quot;age&quot;.getBytes());</span><br><span class="line">		System.out.println(new String(value));</span><br><span class="line">		</span><br><span class="line">		</span><br><span class="line">		table.close();</span><br><span class="line">		conn.close();</span><br><span class="line">		</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	/*</span><br><span class="line">	 * 按行键范围查询数据</span><br><span class="line">	 */</span><br><span class="line">	@Test</span><br><span class="line">	public void testScan() throws Exception&#123;</span><br><span class="line">		/*查询指定行范围数据</span><br><span class="line">		 0</span><br><span class="line">		 1</span><br><span class="line">		 10</span><br><span class="line">		 100</span><br><span class="line">		 1000</span><br><span class="line">		 10000</span><br><span class="line">		 </span><br><span class="line">		 Scan scan = new Scan(&quot;10&quot;.getBytes(), &quot;10000\000&quot;.getBytes());</span><br><span class="line">		 //查询的就是10 ---- 100000之间的数据</span><br><span class="line">		*/</span><br><span class="line">		</span><br><span class="line">		Table table = conn.getTable(TableName.valueOf(&quot;user_info&quot;));</span><br><span class="line">		//包含起始行键 不包含最终行键,如果真的想查询出末尾行键，就可以在末尾行键插入一个不可见字符\0</span><br><span class="line">		Scan scan = new Scan(&quot;10&quot;.getBytes(), &quot;1000\0&quot;.getBytes());</span><br><span class="line">		ResultScanner scanner = table.getScanner(scan);</span><br><span class="line">		Iterator&lt;Result&gt; iterator = scanner.iterator();</span><br><span class="line">		while(iterator.hasNext()) &#123;</span><br><span class="line">			Result result = iterator.next();</span><br><span class="line">			</span><br><span class="line">			CellScanner cellScanner = result.cellScanner();</span><br><span class="line">			</span><br><span class="line">			//遍历整行所有的key value</span><br><span class="line">			while(cellScanner.advance()) &#123;</span><br><span class="line">				Cell cell = cellScanner.current();</span><br><span class="line">				byte[] rowArray = cell.getRowArray();</span><br><span class="line">				byte[] familyArray = cell.getFamilyArray(); //列族名的字节数组</span><br><span class="line">				byte[] qualifierArray = cell.getQualifierArray(); //列名的字节数组</span><br><span class="line">				byte[] valueArray = cell.getValueArray(); //拿到value的字节数组</span><br><span class="line">				System.out.println(&quot;行键&quot;+new String(rowArray,cell.getRowOffset(),cell.getRowLength()));</span><br><span class="line">				System.out.println(&quot;列族名&quot;+new String(familyArray,cell.getFamilyOffset(),cell.getFamilyLength()));</span><br><span class="line">				System.out.println(&quot;列名&quot;+new String(qualifierArray,cell.getQualifierOffset(),cell.getQualifierLength()));</span><br><span class="line">				System.out.println(&quot;value:&quot;+new String(valueArray,cell.getValueOffset(),cell.getValueLength()));</span><br><span class="line">				</span><br><span class="line">			&#125;</span><br><span class="line">			System.out.println(&quot;--------------------&quot;);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	/*</span><br><span class="line">	 * 循环插入大量数据</span><br><span class="line">	 */</span><br><span class="line">	</span><br><span class="line">	@Test</span><br><span class="line">	public void testManyPuts() throws Exception&#123;</span><br><span class="line">		</span><br><span class="line">		Table table = conn.getTable(TableName.valueOf(&quot;user_info&quot;));</span><br><span class="line">		ArrayList&lt;Put&gt; arrayList = new ArrayList&lt;&gt;();</span><br><span class="line">		</span><br><span class="line">		for(int i=0;i&lt;1000;i++) &#123;</span><br><span class="line">			Put put = new Put(Bytes.toBytes(&quot;&quot;+i));</span><br><span class="line">			put.addColumn(Bytes.toBytes(&quot;base_info&quot;), Bytes.toBytes(&quot;username&quot;), Bytes.toBytes(&quot;zhangsan&quot;+i));</span><br><span class="line">			put.addColumn(Bytes.toBytes(&quot;base_info&quot;), Bytes.toBytes(&quot;age&quot;), Bytes.toBytes(18+i));</span><br><span class="line">			put.addColumn(Bytes.toBytes(&quot;extra_info&quot;), Bytes.toBytes(&quot;home&quot;), Bytes.toBytes(&quot;zhangsan&quot;+i));</span><br><span class="line"></span><br><span class="line">			arrayList.add(put);</span><br><span class="line">		&#125;</span><br><span class="line">		</span><br><span class="line">		table.put(arrayList);</span><br><span class="line">		</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h6 id="HBASE-Client-Demo"><a href="#HBASE-Client-Demo" class="headerlink" title="HBASE Client Demo"></a>HBASE Client Demo</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br></pre></td><td class="code"><pre><span class="line">package clientDemo;</span><br><span class="line"></span><br><span class="line">import org.apache.hadoop.conf.Configuration;</span><br><span class="line">import org.apache.hadoop.hbase.HBaseConfiguration;</span><br><span class="line">import org.apache.hadoop.hbase.HColumnDescriptor;</span><br><span class="line">import org.apache.hadoop.hbase.HTableDescriptor;</span><br><span class="line">import org.apache.hadoop.hbase.TableName;</span><br><span class="line">import org.apache.hadoop.hbase.client.Admin;</span><br><span class="line">import org.apache.hadoop.hbase.client.Connection;</span><br><span class="line">import org.apache.hadoop.hbase.client.ConnectionFactory;</span><br><span class="line">import org.apache.hadoop.hbase.regionserver.BloomType;</span><br><span class="line">import org.junit.Before;</span><br><span class="line">import org.junit.Test;</span><br><span class="line"></span><br><span class="line">public class HbaseClientDemo &#123;</span><br><span class="line"></span><br><span class="line">	Configuration conf=null;</span><br><span class="line">	Connection connection=null;</span><br><span class="line">	</span><br><span class="line">	//建立hbase的连接</span><br><span class="line">	@Before</span><br><span class="line">	public void getConn() throws Exception&#123;</span><br><span class="line">		//构造一个连接对象</span><br><span class="line">		conf = HBaseConfiguration.create();</span><br><span class="line">		</span><br><span class="line">		conf.set(&quot;hbase.zookeeper.quorum&quot;, &quot;namenode:2181,datanode1:2181,datanode2:2181,datanode3:2181&quot;);</span><br><span class="line">		</span><br><span class="line">		connection = ConnectionFactory.createConnection(conf);</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	//hbase的创建表</span><br><span class="line">	</span><br><span class="line">	@Test</span><br><span class="line">	public void testCreateTable() throws Exception&#123;</span><br><span class="line">		</span><br><span class="line">		//从连接 中构造一个DDL操作器</span><br><span class="line">		Admin admin = connection.getAdmin();</span><br><span class="line">		</span><br><span class="line">		//创建一个表定义描述对象</span><br><span class="line">		HTableDescriptor hTableDescriptor = new HTableDescriptor(TableName.valueOf(&quot;user_info&quot;));</span><br><span class="line">		</span><br><span class="line">		//创建列族定义描述对象</span><br><span class="line">		HColumnDescriptor hColumnDescriptor_1 = new HColumnDescriptor(&quot;base_info&quot;);</span><br><span class="line">		hColumnDescriptor_1.setMaxVersions(3); //设置该列祖中存储数据的最大版本数，默认是1</span><br><span class="line">		</span><br><span class="line">		HColumnDescriptor hColumnDescriptor_2 = new HColumnDescriptor(&quot;extra_info&quot;);</span><br><span class="line"></span><br><span class="line">		//将列族定义信息对象装入表定义对象中</span><br><span class="line">		hTableDescriptor.addFamily(hColumnDescriptor_1);</span><br><span class="line">		hTableDescriptor.addFamily(hColumnDescriptor_2);</span><br><span class="line">		</span><br><span class="line">		//用DDL操作对象：admin来建表</span><br><span class="line">		admin.createTable(hTableDescriptor);</span><br><span class="line">		</span><br><span class="line">		//关闭链接</span><br><span class="line">		admin.close();</span><br><span class="line">		connection.close();</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	//hbase的修改表</span><br><span class="line">	@Test</span><br><span class="line">	public void testDropTable() throws Exception &#123;</span><br><span class="line">		</span><br><span class="line">		Admin admin = connection.getAdmin();</span><br><span class="line">		</span><br><span class="line">		//删除表</span><br><span class="line">		admin.disableTable(TableName.valueOf(&quot;user_info&quot;));</span><br><span class="line">		admin.deleteTable(TableName.valueOf(&quot;user_info&quot;));</span><br><span class="line">	</span><br><span class="line">		admin.close();</span><br><span class="line">		connection.close();</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	//修改表定义--添加一个列族</span><br><span class="line">	@Test</span><br><span class="line">	public void testAlterTable() throws Exception&#123;</span><br><span class="line"></span><br><span class="line">		Admin admin = connection.getAdmin();</span><br><span class="line">		</span><br><span class="line">		//取出旧的表定义信息</span><br><span class="line">		HTableDescriptor tableDescriptor = admin.getTableDescriptor(TableName.valueOf(&quot;user_info&quot;));</span><br><span class="line">		//新构造一个列族定义</span><br><span class="line">		HColumnDescriptor hColumnDescriptor = new HColumnDescriptor(&quot;other_info&quot;);</span><br><span class="line">		//设置该列族的布隆过滤器类型</span><br><span class="line">		hColumnDescriptor.setBloomFilterType(BloomType.ROWCOL);</span><br><span class="line">		</span><br><span class="line">		//将列族定义添加到表定义对象中</span><br><span class="line">		tableDescriptor.addFamily(hColumnDescriptor);</span><br><span class="line">		</span><br><span class="line">		//将修改过的表定义交给admin去提交</span><br><span class="line">		admin.modifyTable(TableName.valueOf(&quot;user_info&quot;),tableDescriptor );</span><br><span class="line">		</span><br><span class="line">		admin.close();</span><br><span class="line">		connection.close();</span><br><span class="line">		</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line"></span><br><span class="line">	</span><br><span class="line">	</span><br><span class="line">	</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://blogoflyt.cn/2019/02/06/HBASE安装部署/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Richard">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/gakki.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="积累技术之路">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/02/06/HBASE安装部署/" itemprop="url">HBASE安装部署</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-02-06T20:12:00+08:00">
                2019-02-06
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/HBASE/" itemprop="url" rel="index">
                    <span itemprop="name">HBASE</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h5 id="概念特性"><a href="#概念特性" class="headerlink" title="概念特性"></a>概念特性</h5><blockquote>
<p>HBASE是一个数据库—-可以提供数据的实时随机读写</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">HBASE与mysql、oralce、db2等关系型数据库不同，它是一个NOSQL数据库</span><br><span class="line">Hbase的表模型与关系型数据库的表模型不同：</span><br><span class="line">Hbase的表没有固定的字段定义；</span><br><span class="line">Hbase的表中每行存储的都是一些key-value对</span><br><span class="line">Hbase的表中有列族的划分，用户可以指定将哪些kv插入哪个列族</span><br><span class="line">Hbase的表在物理存储上，是按照列族来分割的，不同列族的数据一定存储在不同的文件中</span><br><span class="line">Hbase的表中的每一行都固定有一个行键，而且每一行的行键在表中不能重复</span><br><span class="line">Hbase中的数据，包含行键，包含key，包含value，都是byte[ ]类型，hbase不负责为用户维护数据类型</span><br></pre></td></tr></table></figure>
<blockquote>
<p>HBASE相比于其他nosql数据库的特点：<br>Hbase的表数据存储在HDFS文件系统中<br>从而，hbase具备如下特性：存储容量可以线性扩展； 数据存储的安全性可靠性极高！</p>
</blockquote>
<h5 id="应用场景举例"><a href="#应用场景举例" class="headerlink" title="应用场景举例"></a>应用场景举例</h5><p><a href="https://imgchr.com/i/kxcyI1" target="_blank" rel="noopener"><img src="https://s2.ax1x.com/2019/03/07/kxcyI1.png" alt="kxcyI1.png"></a></p>
<h5 id="安装HBASE"><a href="#安装HBASE" class="headerlink" title="安装HBASE"></a>安装HBASE</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">HBASE是一个分布式系统</span><br><span class="line">其中有一个管理角色：  HMaster(一般2台，一台active，一台backup)</span><br><span class="line">其他的数据节点角色：  HRegionServer(很多台，看数据容量)</span><br></pre></td></tr></table></figure>
<h6 id="安装准备："><a href="#安装准备：" class="headerlink" title="安装准备："></a>安装准备：</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">首先，要有一个HDFS集群，并正常运行； regionserver应该跟hdfs中的datanode在一起</span><br><span class="line">其次，还需要一个zookeeper集群，并正常运行</span><br><span class="line">然后，安装HBASE</span><br><span class="line">角色分配如下：</span><br><span class="line">Hdp01:  namenode  datanode  regionserver  hmaster  zookeeper</span><br><span class="line">Hdp02:  datanode   regionserver  zookeeper</span><br><span class="line">Hdp03:  datanode   regionserver  zookeeper</span><br></pre></td></tr></table></figure>
<h6 id="安装步骤："><a href="#安装步骤：" class="headerlink" title="安装步骤："></a>安装步骤：</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">安装zookeeper(略)</span><br><span class="line">安装hbase</span><br><span class="line">解压hbase安装包</span><br><span class="line">修改hbase-env.sh</span><br><span class="line">export JAVA_HOME=/root/apps/jdk1.7.0_67</span><br><span class="line">export HBASE_MANAGES_ZK=false</span><br><span class="line"></span><br><span class="line">修改hbase-site.xml</span><br><span class="line">	&lt;configuration&gt;</span><br><span class="line">		&lt;!-- 指定hbase在HDFS上存储的路径 --&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">                &lt;name&gt;hbase.rootdir&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;hdfs://hdp01:9000/hbase&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">		&lt;!-- 指定hbase是分布式的 --&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">                &lt;name&gt;hbase.cluster.distributed&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;true&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">		&lt;!-- 指定zk的地址，多个用“,”分割 --&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">                &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;hdp01:2181,hdp02:2181,hdp03:2181&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">	&lt;/configuration&gt;</span><br><span class="line"></span><br><span class="line">修改 regionservers</span><br><span class="line">hdp01</span><br><span class="line">hdp02</span><br><span class="line">hdp03</span><br><span class="line"></span><br><span class="line">启动hbase集群：</span><br><span class="line">bin/start-hbase.sh</span><br><span class="line"></span><br><span class="line">启动完后，还可以在集群中找任意一台机器启动一个备用的master</span><br><span class="line">bin/hbase-daemon.sh start master</span><br><span class="line">新启的这个master会处于backup状态</span><br><span class="line"></span><br><span class="line">启动hbase的命令行客户端</span><br><span class="line">bin/hbase shell</span><br><span class="line">Hbase&gt; list     // 查看表</span><br><span class="line">Hbase&gt; status   // 查看集群状态</span><br><span class="line">Hbase&gt; version  // 查看集群版本</span><br></pre></td></tr></table></figure>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://blogoflyt.cn/2019/02/05/Hive学习笔记-综合查询案例/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Richard">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/gakki.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="积累技术之路">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/02/05/Hive学习笔记-综合查询案例/" itemprop="url">Hive学习笔记-----综合查询案例</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-02-05T15:11:00+08:00">
                2019-02-05
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Hive/" itemprop="url" rel="index">
                    <span itemprop="name">Hive</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h5 id="用hql来做wordcount"><a href="#用hql来做wordcount" class="headerlink" title="用hql来做wordcount"></a>用hql来做wordcount</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">有以下文本文件：</span><br><span class="line">hello tom hello jim</span><br><span class="line">hello rose hello tom</span><br><span class="line">tom love rose rose love jim</span><br><span class="line">jim love tom love is what</span><br><span class="line">what is love</span><br><span class="line"></span><br><span class="line">需要用hive做wordcount</span><br><span class="line">-- 建表映射</span><br><span class="line">create table t_wc(sentence string);</span><br><span class="line"></span><br><span class="line">-- 导入数据</span><br><span class="line">load data local inpath &apos;/root/hivetest/xx.txt&apos; into table t_wc;</span><br></pre></td></tr></table></figure>
<h6 id="hql答案："><a href="#hql答案：" class="headerlink" title="hql答案："></a>hql答案：</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">SELECT word</span><br><span class="line">    ,count(1) as cnts</span><br><span class="line">FROM (</span><br><span class="line">    SELECT explode(split(sentence, &apos; &apos;)) AS word</span><br><span class="line">    FROM t_wc</span><br><span class="line">    ) tmp</span><br><span class="line">GROUP BY word</span><br><span class="line">order by cnts desc</span><br><span class="line">;</span><br></pre></td></tr></table></figure>
<h5 id="级联报表查询"><a href="#级联报表查询" class="headerlink" title="级联报表查询"></a>级联报表查询</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">有如下数据：</span><br><span class="line"></span><br><span class="line">A,2015-01,5</span><br><span class="line">A,2015-01,15</span><br><span class="line">B,2015-01,5</span><br><span class="line">A,2015-01,8</span><br><span class="line">B,2015-01,25</span><br><span class="line">A,2015-01,5</span><br><span class="line">C,2015-01,10</span><br><span class="line">C,2015-01,20</span><br><span class="line">A,2015-02,4</span><br><span class="line">A,2015-02,6</span><br><span class="line">C,2015-02,30</span><br><span class="line">C,2015-02,10</span><br><span class="line">B,2015-02,10</span><br><span class="line">B,2015-02,5</span><br><span class="line">A,2015-03,14</span><br><span class="line">A,2015-03,6</span><br><span class="line">B,2015-03,20</span><br><span class="line">B,2015-03,25</span><br><span class="line">C,2015-03,10</span><br><span class="line">C,2015-03,20</span><br><span class="line"></span><br><span class="line">建表映射：</span><br><span class="line">create table t_access_times(username string,month string,counts int)</span><br><span class="line">row format delimited fields terminated by &apos;,&apos;;</span><br><span class="line"></span><br><span class="line">需要要开发hql脚本，来统计出如下累计报表：</span><br><span class="line">用户	月份	月总额	累计到当月的总额</span><br><span class="line">A	2015-01	33	33</span><br><span class="line">A	2015-02	10	43</span><br><span class="line">A	2015-03	30	73</span><br><span class="line">B	2015-01	30	30</span><br><span class="line">B	2015-02	15	45</span><br></pre></td></tr></table></figure>
<h6 id="答案"><a href="#答案" class="headerlink" title="答案"></a>答案</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line">1、第一步，先求个用户的月总金额</span><br><span class="line">select username,month,sum(salary) as salary from t_access_times group by username,month</span><br><span class="line"></span><br><span class="line">+-----------+----------+---------+--+</span><br><span class="line">| username  |  month   | salary  |</span><br><span class="line">+-----------+----------+---------+--+</span><br><span class="line">| A         | 2015-01  | 33      |</span><br><span class="line">| A         | 2015-02  | 10      |</span><br><span class="line">| B         | 2015-01  | 30      |</span><br><span class="line">| B         | 2015-02  | 15      |</span><br><span class="line">+-----------+----------+---------+--+</span><br><span class="line"></span><br><span class="line">2、第二步，将月总金额表自己连接 自己连接</span><br><span class="line">create table t_tmp2 (auname string,amonth string,acnts int,buname string,bmonth string,bcnts int)</span><br><span class="line">as</span><br><span class="line">select A.*,B.* FROM</span><br><span class="line">(select username,month,sum(salary) as salary from t_access_times group by username,month) A </span><br><span class="line">inner join </span><br><span class="line">(select username,month,sum(salary) as salary from t_access_times group by username,month) B</span><br><span class="line">on</span><br><span class="line">A.username=B.username</span><br><span class="line">where B.month &lt;= A.month</span><br><span class="line">+-------------+----------+-----------+-------------+----------+-----------+--+</span><br><span class="line">| a.username  | a.month  | a.salary  | b.username  | b.month  | b.salary  |</span><br><span class="line">+-------------+----------+-----------+-------------+----------+-----------+--+</span><br><span class="line">| A           | 2015-01  | 33        | A           | 2015-01  | 33        |</span><br><span class="line">| A           | 2015-01  | 33        | A           | 2015-02  | 10        |</span><br><span class="line">| A           | 2015-02  | 10        | A           | 2015-01  | 33        |</span><br><span class="line">| A           | 2015-02  | 10        | A           | 2015-02  | 10        |</span><br><span class="line">| B           | 2015-01  | 30        | B           | 2015-01  | 30        |</span><br><span class="line">| B           | 2015-01  | 30        | B           | 2015-02  | 15        |</span><br><span class="line">| B           | 2015-02  | 15        | B           | 2015-01  | 30        |</span><br><span class="line">| B           | 2015-02  | 15        | B           | 2015-02  | 15        |</span><br><span class="line">+-------------+----------+-----------+-------------+----------+-----------+--+</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">第3步：</span><br><span class="line">select auname,amonth,acnts,sum(bcnts)</span><br><span class="line">from t_tmp2</span><br><span class="line">group by auname,amonth,acnts;</span><br><span class="line">得到最终结果</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">当然，也可以把整个逻辑过程写成一个SQL语句：</span><br><span class="line"></span><br><span class="line">select A.username,A.month,max(A.salary) as salary,sum(B.salary) as accumulate</span><br><span class="line">from </span><br><span class="line">(select username,month,sum(salary) as salary from t_access_times group by username,month) A </span><br><span class="line">inner join </span><br><span class="line">(select username,month,sum(salary) as salary from t_access_times group by username,month) B</span><br><span class="line">on</span><br><span class="line">A.username=B.username</span><br><span class="line">where B.month &lt;= A.month</span><br><span class="line">group by A.username,A.month</span><br><span class="line">order by A.username,A.month;</span><br></pre></td></tr></table></figure>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://blogoflyt.cn/2019/02/04/Hive学习笔记-函数使用/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Richard">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/gakki.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="积累技术之路">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/02/04/Hive学习笔记-函数使用/" itemprop="url">Hive学习笔记-----函数使用</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-02-04T14:00:00+08:00">
                2019-02-04
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Hive/" itemprop="url" rel="index">
                    <span itemprop="name">Hive</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h5 id="常用内置函数"><a href="#常用内置函数" class="headerlink" title="常用内置函数"></a>常用内置函数</h5><h6 id="类型转换函数"><a href="#类型转换函数" class="headerlink" title="类型转换函数"></a>类型转换函数</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">select cast(&quot;5&quot; as int) from dual;</span><br><span class="line">select cast(&quot;2017-08-03&quot; as date) ;</span><br><span class="line">select cast(current_timestamp as date);</span><br><span class="line"></span><br><span class="line">示例：</span><br><span class="line">1	1995-05-05 13:30:59	1200.3</span><br><span class="line">2	1994-04-05 13:30:59	2200</span><br><span class="line">3	1996-06-01 12:20:30	80000.5</span><br><span class="line">create table t_fun(id string,birthday string,salary string)</span><br><span class="line">row format delimited fields terminated by &apos;,&apos;;</span><br><span class="line"></span><br><span class="line">select id,cast(birthday as date) as bir,cast(salary as float) from t_fun;</span><br></pre></td></tr></table></figure>
<h6 id="数学运算函数"><a href="#数学运算函数" class="headerlink" title="数学运算函数"></a>数学运算函数</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">select round(5.4) from dual;   ## 5</span><br><span class="line">select round(5.1345,3) from dual;  ##5.135</span><br><span class="line">select ceil(5.4) from dual; // select ceiling(5.4) from dual;   ## 6</span><br><span class="line">select floor(5.4) from dual;  ## 5</span><br><span class="line">select abs(-5.4) from dual;  ## 5.4</span><br><span class="line">select greatest(3,5,6) from dual;  ## 6 </span><br><span class="line">select least(3,5,6) from dual;</span><br><span class="line"></span><br><span class="line">示例：</span><br><span class="line">有表如下：</span><br></pre></td></tr></table></figure>
<p><a href="https://imgchr.com/i/kxFKXV" target="_blank" rel="noopener"><img src="https://s2.ax1x.com/2019/03/07/kxFKXV.png" alt="kxFKXV.png"></a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">select greatest(cast(s1 as double),cast(s2 as double),cast(s3 as double)) from t_fun2;</span><br><span class="line">结果：</span><br><span class="line">+---------+--+</span><br><span class="line">|   _c0   |</span><br><span class="line">+---------+--+</span><br><span class="line">| 2000.0  |</span><br><span class="line">| 9800.0  |</span><br><span class="line">+---------+--+</span><br><span class="line"></span><br><span class="line">select max(age) from t_person;    聚合函数</span><br><span class="line">select min(age) from t_person;    聚合函数</span><br></pre></td></tr></table></figure>
<h6 id="字符串函数"><a href="#字符串函数" class="headerlink" title="字符串函数"></a>字符串函数</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">substr(string, int start)   ## 截取子串</span><br><span class="line">substring(string, int start)</span><br><span class="line">示例：select substr(&quot;abcdefg&quot;,2) from dual;</span><br><span class="line"></span><br><span class="line">substr(string, int start, int len) </span><br><span class="line">substring(string, int start, int len)</span><br><span class="line">示例：select substr(&quot;abcdefg&quot;,2,3) from dual;</span><br><span class="line"></span><br><span class="line">concat(string A, string B...)  ## 拼接字符串</span><br><span class="line">concat_ws(string SEP, string A, string B...)</span><br><span class="line">示例：select concat(&quot;ab&quot;,&quot;xy&quot;) from dual;</span><br><span class="line">select concat_ws(&quot;.&quot;,&quot;192&quot;,&quot;168&quot;,&quot;33&quot;,&quot;44&quot;) from dual;</span><br><span class="line"></span><br><span class="line">length(string A)</span><br><span class="line">示例：select length(&quot;192.168.33.44&quot;) from dual;</span><br><span class="line"></span><br><span class="line">split(string str, string pat)</span><br><span class="line">示例：select split(&quot;192.168.33.44&quot;,&quot;.&quot;) from dual; 错误的，因为.号是正则语法中的特定字符</span><br><span class="line">select split(&quot;192.168.33.44&quot;,&quot;\\.&quot;) from dual;</span><br><span class="line"></span><br><span class="line">upper(string str) ##转大写</span><br></pre></td></tr></table></figure>
<h6 id="时间函数"><a href="#时间函数" class="headerlink" title="时间函数"></a>时间函数</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">select current_timestamp; </span><br><span class="line">select current_date;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">## 取当前时间的毫秒数时间戳 </span><br><span class="line">select unix_timestamp();</span><br><span class="line"></span><br><span class="line">## unix时间戳转字符串</span><br><span class="line">from_unixtime(bigint unixtime[, string format])</span><br><span class="line">示例：select from_unixtime(unix_timestamp());</span><br><span class="line">select from_unixtime(unix_timestamp(),&quot;yyyy/MM/dd HH:mm:ss&quot;);</span><br><span class="line"></span><br><span class="line">## 字符串转unix时间戳</span><br><span class="line">unix_timestamp(string date, string pattern)</span><br><span class="line">示例： select unix_timestamp(&quot;2017-08-10 17:50:30&quot;);</span><br><span class="line">select unix_timestamp(&quot;2017/08/10 17:50:30&quot;,&quot;yyyy/MM/dd HH:mm:ss&quot;);</span><br><span class="line">## 将字符串转成日期date</span><br><span class="line">select to_date(&quot;2017-09-17 16:58:32&quot;);</span><br></pre></td></tr></table></figure>
<h6 id="表生成函数"><a href="#表生成函数" class="headerlink" title="表生成函数"></a>表生成函数</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">行转列函数：explode()</span><br><span class="line">假如有以下数据：</span><br><span class="line">1,zhangsan,化学:物理:数学:语文</span><br><span class="line">2,lisi,化学:数学:生物:生理:卫生</span><br><span class="line">3,wangwu,化学:语文:英语:体育:生物</span><br><span class="line">映射成一张表：</span><br><span class="line">create table t_stu_subject(id int,name string,subjects array&lt;string&gt;)</span><br><span class="line">row format delimited fields terminated by &apos;,&apos;</span><br><span class="line">collection items terminated by &apos;:&apos;;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">使用explode()对数组字段“炸裂”</span><br></pre></td></tr></table></figure>
<p><a href="https://imgchr.com/i/kxFc9A" target="_blank" rel="noopener"><img src="https://s2.ax1x.com/2019/03/07/kxFc9A.png" alt="kxFc9A.png"></a><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">然后，我们利用这个explode的结果，来求去重的课程：</span><br><span class="line">select distinct tmp.sub</span><br><span class="line">from </span><br><span class="line">(select explode(subjects) as sub from t_stu_subject) tmp;</span><br></pre></td></tr></table></figure></p>
<h6 id="表生成函数lateral-view"><a href="#表生成函数lateral-view" class="headerlink" title="表生成函数lateral view"></a>表生成函数lateral view</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">select id,name,tmp.sub </span><br><span class="line">from t_stu_subject lateral view explode(subjects) tmp as sub;</span><br></pre></td></tr></table></figure>
<p><a href="https://imgchr.com/i/kxFRjP" target="_blank" rel="noopener"><img src="https://s2.ax1x.com/2019/03/07/kxFRjP.png" alt="kxFRjP.png"></a><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">理解： lateral view 相当于两个表在join</span><br><span class="line">左表：是原表</span><br><span class="line">右表：是explode(某个集合字段)之后产生的表</span><br><span class="line">而且：这个join只在同一行的数据间进行</span><br><span class="line"></span><br><span class="line">那样，可以方便做更多的查询：</span><br><span class="line">比如，查询选修了生物课的同学</span><br><span class="line">select a.id,a.name,a.sub from </span><br><span class="line">(select id,name,tmp.sub as sub from t_stu_subject lateral view explode(subjects) tmp as sub) a</span><br><span class="line">where sub=&apos;生物&apos;;</span><br></pre></td></tr></table></figure></p>
<h6 id="集合函数"><a href="#集合函数" class="headerlink" title="集合函数"></a>集合函数</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">array_contains(Array&lt;T&gt;, value)  返回boolean值</span><br><span class="line"></span><br><span class="line">示例：</span><br><span class="line">select moive_name,array_contains(actors,&apos;吴刚&apos;) from t_movie;</span><br><span class="line">select array_contains(array(&apos;a&apos;,&apos;b&apos;,&apos;c&apos;),&apos;c&apos;) from dual;</span><br><span class="line"></span><br><span class="line">sort_array(Array&lt;T&gt;) 返回排序后的数组</span><br><span class="line"></span><br><span class="line">示例：</span><br><span class="line">select sort_array(array(&apos;c&apos;,&apos;b&apos;,&apos;a&apos;)) from dual;</span><br><span class="line">select &apos;haha&apos;,sort_array(array(&apos;c&apos;,&apos;b&apos;,&apos;a&apos;)) as xx from (select 0) tmp;</span><br><span class="line"></span><br><span class="line">size(Array&lt;T&gt;)  返回一个int值</span><br><span class="line"></span><br><span class="line">示例：</span><br><span class="line">select moive_name,size(actors) as actor_number from t_movie;</span><br><span class="line"></span><br><span class="line">size(Map&lt;K.V&gt;)  返回一个int值</span><br><span class="line">map_keys(Map&lt;K.V&gt;)  返回一个数组</span><br><span class="line">map_values(Map&lt;K.V&gt;) 返回一个数组</span><br></pre></td></tr></table></figure>
<h6 id="条件控制函数"><a href="#条件控制函数" class="headerlink" title="条件控制函数"></a>条件控制函数</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">case when </span><br><span class="line">语法：</span><br><span class="line">CASE   [ expression ]</span><br><span class="line">       WHEN condition1 THEN result1</span><br><span class="line">       WHEN condition2 THEN result2</span><br><span class="line">       ...</span><br><span class="line">       WHEN conditionn THEN resultn</span><br><span class="line">       ELSE result</span><br><span class="line">END</span><br><span class="line"></span><br><span class="line">示例：</span><br><span class="line">select id,name,</span><br><span class="line">case</span><br><span class="line">when age&lt;28 then &apos;youngth&apos;</span><br><span class="line">when age&gt;27 and age&lt;40 then &apos;zhongnian&apos;</span><br><span class="line">else &apos;old&apos;</span><br><span class="line">end</span><br><span class="line">from t_user;</span><br><span class="line"></span><br><span class="line">IF</span><br><span class="line">select id,if(age&gt;25,&apos;working&apos;,&apos;worked&apos;) from t_user;</span><br><span class="line"></span><br><span class="line"> select movie_name,if(array_contains(actors,&apos;wugang&apos;),&apos;goodmovie&apos;,&apos;badmovie&apos;) from t_movie;</span><br></pre></td></tr></table></figure>
<h6 id="json解析函数：表生成函数"><a href="#json解析函数：表生成函数" class="headerlink" title="json解析函数：表生成函数"></a>json解析函数：表生成函数</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">json_tuple函数</span><br><span class="line">示例：</span><br><span class="line">select json_tuple(json,&apos;movie&apos;,&apos;rate&apos;,&apos;timeStamp&apos;,&apos;uid&apos;) as(movie,rate,ts,uid) from t_rating_json;</span><br><span class="line">产生结果：</span><br></pre></td></tr></table></figure>
<p><a href="https://imgchr.com/i/kxFb3n" target="_blank" rel="noopener"><img src="https://s2.ax1x.com/2019/03/07/kxFb3n.png" alt="kxFb3n.png"></a><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">利用json_tuple从原始json数据表中，etl出一个详细信息表：</span><br><span class="line">create table t_rate </span><br><span class="line">as </span><br><span class="line">select </span><br><span class="line">uid,</span><br><span class="line">movie,</span><br><span class="line">rate,</span><br><span class="line">year(from_unixtime(cast(ts as bigint))) as year,</span><br><span class="line">month(from_unixtime(cast(ts as bigint))) as month,</span><br><span class="line">day(from_unixtime(cast(ts as bigint))) as day,</span><br><span class="line">hour(from_unixtime(cast(ts as bigint))) as hour,</span><br><span class="line">minute(from_unixtime(cast(ts as bigint))) as minute,</span><br><span class="line">from_unixtime(cast(ts as bigint)) as ts</span><br><span class="line">from </span><br><span class="line">(select </span><br><span class="line">json_tuple(rateinfo,&apos;movie&apos;,&apos;rate&apos;,&apos;timeStamp&apos;,&apos;uid&apos;) as(movie,rate,ts,uid)</span><br><span class="line">from t_json) tmp</span><br><span class="line">;</span><br></pre></td></tr></table></figure></p>
<h6 id="分析函数：row-number-over-——分组TOPN"><a href="#分析函数：row-number-over-——分组TOPN" class="headerlink" title="分析函数：row_number() over()——分组TOPN"></a>分析函数：row_number() over()——分组TOPN</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">需求</span><br><span class="line">有如下数据：</span><br><span class="line">1,18,a,male</span><br><span class="line">2,19,b,male</span><br><span class="line">3,22,c,female</span><br><span class="line">4,16,d,female</span><br><span class="line">5,30,e,male</span><br><span class="line">6,26,f,female</span><br><span class="line"></span><br><span class="line">需要查询出每种性别中年龄最大的2条数据</span><br><span class="line"></span><br><span class="line">实现：</span><br><span class="line">使用row_number函数，对表中的数据按照性别分组，按照年龄倒序排序并进行标记</span><br><span class="line"></span><br><span class="line">hql代码：</span><br><span class="line">select id,age,name,sex,</span><br><span class="line">row_number() over(partition by sex order by age desc) as rank</span><br><span class="line">from t_rownumber</span><br><span class="line"></span><br><span class="line">产生结果：</span><br></pre></td></tr></table></figure>
<p><a href="https://imgchr.com/i/kxFqcq" target="_blank" rel="noopener"><img src="https://s2.ax1x.com/2019/03/07/kxFqcq.png" alt="kxFqcq.png"></a><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">然后，利用上面的结果，查询出rank&lt;=2的即为最终需求</span><br><span class="line">select id,age,name,sex</span><br><span class="line">from </span><br><span class="line">(select id,age,name,sex,</span><br><span class="line">row_number() over(partition by sex order by age desc) as rank</span><br><span class="line">from t_rownumber) tmp</span><br><span class="line">where rank&lt;=2;</span><br></pre></td></tr></table></figure></p>
<h6 id="自定义函数"><a href="#自定义函数" class="headerlink" title="自定义函数"></a>自定义函数</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">需求：</span><br><span class="line">需要对json数据表中的json数据写一个自定义函数，用于传入一个json，返回一个数据值的数组</span><br><span class="line"></span><br><span class="line">json原始数据表：</span><br></pre></td></tr></table></figure>
<p><a href="https://imgchr.com/i/kxFjBT" target="_blank" rel="noopener"><img src="https://s2.ax1x.com/2019/03/07/kxFjBT.png" alt="kxFjBT.png"></a></p>
<blockquote>
<p>需要做ETL操作，将json数据变成普通表数据，插入另一个表中：<br><a href="https://imgchr.com/i/kxFzEF" target="_blank" rel="noopener"><img src="https://s2.ax1x.com/2019/03/07/kxFzEF.png" alt="kxFzEF.png"></a></p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">实现步骤：</span><br><span class="line">1、开发JAVA的UDF类</span><br><span class="line">public class ParseJson extends UDF&#123;</span><br><span class="line">	</span><br><span class="line">	// 重载 ：返回值类型 和参数类型及个数，完全由用户自己决定</span><br><span class="line">	// 本处需求是：给一个字符串，返回一个数组</span><br><span class="line">	public String[] evaluate(String json) &#123;</span><br><span class="line">		</span><br><span class="line">		String[] split = json.split(&quot;\&quot;&quot;);</span><br><span class="line">		String[] res = new String[]&#123;split[3],split[7],split[11],split[15]&#125;;</span><br><span class="line">		return res;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">2、打jar包</span><br><span class="line"></span><br><span class="line">在eclipse中使用export即可</span><br><span class="line"></span><br><span class="line">3、上传jar包到运行hive所在的linux机器</span><br><span class="line"></span><br><span class="line">4、在hive中创建临时函数：</span><br><span class="line">在hive的提示符中：</span><br><span class="line">hive&gt; add jar /root/jsonparse.jar;</span><br><span class="line">然后，在hive的提示符中，创建一个临时函数：</span><br><span class="line">hive&gt;CREATE  TEMPORARY  FUNCTION  jsonp  AS  &apos;cn.edu360.hdp.hive.ParseJson&apos;;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">5、开发hql语句，利用自定义函数，从原始表中抽取数据插入新表</span><br><span class="line">insert into table t_rate</span><br><span class="line">select </span><br><span class="line">split(jsonp(json),&apos;,&apos;)[0],</span><br><span class="line">cast(split(jsonp(json),&apos;,&apos;)[1] as int),</span><br><span class="line">cast(split(jsonp(json),&apos;,&apos;)[2] as bigint),</span><br><span class="line">cast(split(jsonp(json),&apos;,&apos;)[3] as int)</span><br><span class="line">from </span><br><span class="line">t_rating_json;</span><br><span class="line"></span><br><span class="line">注：临时函数只在一次hive会话中有效，重启会话后就无效</span><br><span class="line"></span><br><span class="line">如果需要经常使用该自定义函数，可以考虑创建永久函数：</span><br><span class="line">拷贝jar包到hive的类路径中：</span><br><span class="line">cp wc.jar apps/hive-1.2.1/lib/</span><br><span class="line">创建了：</span><br><span class="line">create function pfuncx as &apos;com.doit.hive.udf.UserInfoParser&apos;;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">删除函数：</span><br><span class="line">DROP  TEMPORARY  FUNCTION  [IF  EXISTS] function_name  </span><br><span class="line">DROP FUNCTION[IF EXISTS] function_name</span><br></pre></td></tr></table></figure>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://blogoflyt.cn/2019/02/03/Hive学习笔记-DQL/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Richard">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/gakki.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="积累技术之路">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/02/03/Hive学习笔记-DQL/" itemprop="url">Hive学习笔记-----DQL</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-02-03T21:22:00+08:00">
                2019-02-03
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Hive/" itemprop="url" rel="index">
                    <span itemprop="name">Hive</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h5 id="hive查询语法"><a href="#hive查询语法" class="headerlink" title="hive查询语法"></a>hive查询语法</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">提示：在做小数据量查询测试时，可以让hive将mrjob提交给本地运行器运行，可以在hive会话中设置如下参数：</span><br><span class="line">hive&gt; set hive.exec.mode.local.auto=true;</span><br></pre></td></tr></table></figure>
<h6 id="基本查询示例"><a href="#基本查询示例" class="headerlink" title="基本查询示例"></a>基本查询示例</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">select * from t_access;</span><br><span class="line">select count(*) from t_access;</span><br><span class="line">select max(ip) from t_access;</span><br></pre></td></tr></table></figure>
<h6 id="条件查询"><a href="#条件查询" class="headerlink" title="条件查询"></a>条件查询</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">select * from t_access where access_time&lt;&apos;2017-08-06 15:30:20&apos;</span><br><span class="line">select * from t_access where access_time&lt;&apos;2017-08-06 16:30:20&apos; and ip&gt;&apos;192.168.33.3&apos;;</span><br></pre></td></tr></table></figure>
<h6 id="join关联查询示例"><a href="#join关联查询示例" class="headerlink" title="join关联查询示例"></a>join关联查询示例</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">假如有a.txt文件</span><br><span class="line">a,1</span><br><span class="line">b,2</span><br><span class="line">c,3</span><br><span class="line">d,4</span><br><span class="line"></span><br><span class="line">假如有b.txt文件</span><br><span class="line">a,xx</span><br><span class="line">b,yy</span><br><span class="line">d,zz</span><br><span class="line">e,pp</span><br><span class="line"></span><br><span class="line">进行各种join查询：</span><br><span class="line">1、inner join（join）</span><br><span class="line">select </span><br><span class="line">a.name as aname,</span><br><span class="line">a.numb as anumb,</span><br><span class="line">b.name as bname,</span><br><span class="line">b.nick as bnick</span><br><span class="line">from t_a a</span><br><span class="line">join t_b b</span><br><span class="line">on a.name=b.name</span><br><span class="line"></span><br><span class="line">结果：</span><br><span class="line">+--------+--------+--------+--------+--+</span><br><span class="line">| aname  | anumb  | bname  | bnick  |</span><br><span class="line">+--------+--------+--------+--------+--+</span><br><span class="line">| a      | 1      | a      | xx     |</span><br><span class="line">| b      | 2      | b      | yy     |</span><br><span class="line">| d      | 4      | d      | zz     |</span><br><span class="line">+--------+--------+--------+--------+--+</span><br></pre></td></tr></table></figure>
<h6 id="left-outer-join（left-join）"><a href="#left-outer-join（left-join）" class="headerlink" title="left outer join（left join）"></a>left outer join（left join）</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">select </span><br><span class="line">a.name as aname,</span><br><span class="line">a.numb as anumb,</span><br><span class="line">b.name as bname,</span><br><span class="line">b.nick as bnick</span><br><span class="line">from t_a a</span><br><span class="line">left outer join t_b b</span><br><span class="line">on a.name=b.name</span><br></pre></td></tr></table></figure>
<blockquote>
<p>结果<br><a href="https://imgchr.com/i/kv6YzF" target="_blank" rel="noopener"><img src="https://s2.ax1x.com/2019/03/06/kv6YzF.png" alt="kv6YzF.png"></a></p>
</blockquote>
<h6 id="right-outer-join（right-join）"><a href="#right-outer-join（right-join）" class="headerlink" title="right outer join（right join）"></a>right outer join（right join）</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">select </span><br><span class="line">a.name as aname,</span><br><span class="line">a.numb as anumb,</span><br><span class="line">b.name as bname,</span><br><span class="line">b.nick as bnick</span><br><span class="line">from t_a a</span><br><span class="line">right outer join t_b b</span><br><span class="line">on a.name=b.name</span><br></pre></td></tr></table></figure>
<blockquote>
<p>结果<br><a href="https://imgchr.com/i/kv6ri6" target="_blank" rel="noopener"><img src="https://s2.ax1x.com/2019/03/06/kv6ri6.png" alt="kv6ri6.png"></a></p>
</blockquote>
<h6 id="full-outer-join（full-join）"><a href="#full-outer-join（full-join）" class="headerlink" title="full outer join（full join）"></a>full outer join（full join）</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">select </span><br><span class="line">a.name as aname,</span><br><span class="line">a.numb as anumb,</span><br><span class="line">b.name as bname,</span><br><span class="line">b.nick as bnick</span><br><span class="line">from t_a a</span><br><span class="line">full join t_b b</span><br><span class="line">on a.name=b.name;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>结果：<br><a href="https://imgchr.com/i/kv6yRO" target="_blank" rel="noopener"><img src="https://s2.ax1x.com/2019/03/06/kv6yRO.png" alt="kv6yRO.png"></a></p>
</blockquote>
<h6 id="left-semi-join"><a href="#left-semi-join" class="headerlink" title="left semi join"></a>left semi join</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">hive中不支持exist/IN子查询，可以用left semi join来实现同样的效果：</span><br><span class="line">select </span><br><span class="line">a.name as aname,</span><br><span class="line">a.numb as anumb</span><br><span class="line">from t_a a</span><br><span class="line">left semi join t_b b</span><br><span class="line">on a.name=b.name;</span><br></pre></td></tr></table></figure>
<p><a href="https://imgchr.com/i/kv6gQe" target="_blank" rel="noopener"><img src="https://s2.ax1x.com/2019/03/06/kv6gQe.png" alt="kv6gQe.png"></a></p>
<blockquote>
<p>注意： left semi join的 select子句中，不能有右表的字段</p>
</blockquote>
<h6 id="group-by分组聚合"><a href="#group-by分组聚合" class="headerlink" title="group by分组聚合"></a>group by分组聚合</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">select dt,count(*),max(ip) as cnt from t_access group by dt;</span><br><span class="line"></span><br><span class="line">select dt,count(*),max(ip) as cnt from t_access group by dt having dt&gt;&apos;20170804&apos;;</span><br><span class="line"></span><br><span class="line">select </span><br><span class="line">dt,count(*),max(ip) as cnt </span><br><span class="line">from t_access </span><br><span class="line">where url=&apos;http://www.edu360.cn/job&apos;</span><br><span class="line">group by dt having dt&gt;&apos;20170804&apos;;</span><br><span class="line"></span><br><span class="line">注意： 一旦有group by子句，那么，在select子句中就不能有 （分组字段，聚合函数） 以外的字段</span><br><span class="line"></span><br><span class="line">## 为什么where必须写在group by的前面，为什么group by后面的条件只能用having</span><br><span class="line">因为，where是用于在真正执行查询逻辑之前过滤数据用的</span><br><span class="line">having是对group by聚合之后的结果进行再过滤；</span><br><span class="line"></span><br><span class="line">上述语句的执行逻辑：</span><br><span class="line">1、where过滤不满足条件的数据</span><br><span class="line">2、用聚合函数和group by进行数据运算聚合，得到聚合结果</span><br><span class="line">3、用having条件过滤掉聚合结果中不满足条件的数据</span><br></pre></td></tr></table></figure>
<h6 id="子查询"><a href="#子查询" class="headerlink" title="子查询"></a>子查询</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">select id,name,father </span><br><span class="line">from </span><br><span class="line">(select id,name,family_members[&apos;brother&apos;] as father from t_person) tmp</span><br><span class="line">where father is not null;</span><br></pre></td></tr></table></figure>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/2/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><span class="page-number current">3</span><a class="page-number" href="/page/4/">4</a><span class="space">&hellip;</span><a class="page-number" href="/page/6/">6</a><a class="extend next" rel="next" href="/page/4/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/gakki.jpg"
                alt="Richard" />
            
              <p class="site-author-name" itemprop="name">Richard</p>
              <p class="site-description motion-element" itemprop="description">悟已往之不谏,知来者之可追</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">57</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">13</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">79</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          

          
          

          
          
            <div class="links-of-blogroll motion-element links-of-blogroll-block">
              <div class="links-of-blogroll-title">
                <i class="fa  fa-fw fa-link"></i>
                Links
              </div>
              <ul class="links-of-blogroll-list">
                
                  <li class="links-of-blogroll-item">
                    <a href="https://github.com/showiproute" title="Github" target="_blank">Github</a>
                  </li>
                
              </ul>
            </div>
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Richard</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Mist</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
